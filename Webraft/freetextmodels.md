## Webraft Free API Text Models

| Model ID                       | Model Name                     | Endpoint                          | Premium | Free Credits | Description                                                                                                                                 |
|---------------------------------|---------------------------------|-----------------------------------|---------|---------------|---------------------------------------------------------------------------------------------------------------------------------------------------------|
| deepseek-coder-1.3b            | deepseek-coder-1.3b            | /v1/chat/completions            | False   | 500            | A coding-focused model.                                                                                                                             |
| mistral-small                  | mistral-small                  | /v1/chat/completions            | False   | 500            | A smaller, faster, and cheaper alternative to Mistral-medium.                                                                                |
| merlinite-70b                  | merlinite-70b                  | /v1/chat/completions            | False   | 500            | A 70B parameter model trained on a massive dataset of text and code.                                                                           |
| gorilla-openfunctions-v0       | gorilla-openfunctions-v0       | /v1/chat/completions            | False   | 500            | A model specializing in understanding and responding to function calls.                                                                        |
| llama2-uncensored-13b          | llama2-uncensored-13b          | /v1/chat/completions            | False   | 500            | An uncensored version of the Llama 2 13B model.                                                                                              |
| everythinglm-13b               | everythinglm-13b               | /v1/chat/completions            | False   | 500            | A 13B parameter model trained on a large dataset of text and code.                                                                           |
| stable-beluga-13b              | stable-beluga-13b              | /v1/chat/completions            | False   | 500            | A 13B parameter model known for its stability and performance.                                                                                |
| vicuna-13b-16k                 | vicuna-13b-16k                 | /v1/chat/completions            | False   | 500            | A 13B parameter model with a context window of 16k tokens.                                                                                   |
| orca2                         | orca2                         | /v1/chat/completions            | False   | 500            | A model designed for dialogue and conversation.                                                                                                  |
| duckdb-nsql-7b-q4_k_m          | duckdb-nsql-7b-q4_k_m          | /v1/chat/completions            | False   | 500            | A model specializing in natural language queries for DuckDB.                                                                                   |
| neural-chat-7b                 | neural-chat-7b                 | /v1/chat/completions            | False   | 500            | A 7B parameter model designed for conversational AI.                                                                                            |
| wizardlm-uncensored-13b        | wizardlm-uncensored-13b        | /v1/chat/completions            | False   | 500            | An uncensored version of the WizardLM 13B model.                                                                                             |
| smaug-mixtral-v0.1             | smaug-mixtral-v0.1             | /v1/chat/completions            | False   | 500            | A model based on the Mixtral architecture.                                                                                                    |
| opus-v1.2-7b                   | opus-v1.2-7b                   | /v1/chat/completions            | False   | 500            | A 7B parameter model trained on a large dataset of text and code.                                                                           |
| yarn-llama2-7b-128k            | yarn-llama2-7b-128k            | /v1/chat/completions            | False   | 500            | A fine-tuned version of Llama 2 with a context window of 128k tokens.                                                                         |
| liberated-qwen1.5-34b          | liberated-qwen1.5-34b          | /v1/chat/completions            | False   | 500            | A 34B parameter model from the Qwen family.                                                                                                   |
| alfred-40b-1023                | alfred-40b-1023                | /v1/chat/completions            | False   | 500            | A 40B parameter model trained on a large dataset of text and code.                                                                           |
| codellama-13b-python          | codellama-13b-python          | /v1/chat/completions            | False   | 500            | A model specializing in Python code generation.                                                                                              |
| medllama2-70b                  | medllama2-70b                  | /v1/chat/completions            | False   | 500            | A 70B parameter model trained on medical data.                                                                                                |
| phind-codellama-34b-python      | phind-codellama-34b-python      | /v1/chat/completions            | False   | 500            | A 34B parameter model specializing in Python code generation.                                                                               |
| duckdb-nsql-7b                 | duckdb-nsql-7b                 | /v1/chat/completions            | False   | 500            | A model specializing in natural language queries for DuckDB.                                                                                   |
| nous-hermes2-mixtral-8x7b      | nous-hermes2-mixtral-8x7b      | /v1/chat/completions            | False   | 500            | A model based on the Mixtral architecture.                                                                                                    |
| gpt-3.5-turbo-0125             | gpt-3.5-turbo-0125             | /v1/chat/completions            | False   | 500            | A previous version of the GPT-3.5-turbo model.                                                                                              |
| gpt-4                         | gpt-4                         | /v1/chat/completions            | False   | 500            | A powerful large language model.                                                                                                             |
| gpt-3.5-turbo-instruct          | gpt-3.5-turbo-instruct          | /v1/chat/completions            | False   | 500            | A version of GPT-3.5-turbo fine-tuned for following instructions.                                                                             |
| codeup-13b                     | codeup-13b                     | /v1/chat/completions            | False   | 500            | A 13B parameter model trained on a large dataset of code.                                                                                    |
| samantha-mistral-7b-v1.2        | samantha-mistral-7b-v1.2        | /v1/chat/completions            | False   | 500            | A fine-tuned version of Mistral 7B.                                                                                                           |
| labradorite-70b                 | labradorite-70b                 | /v1/chat/completions            | False   | 500            | A 70B parameter model trained on a massive dataset of text and code.                                                                           |
| yarn-llama2-7b-64k             | yarn-llama2-7b-64k             | /v1/chat/completions            | False   | 500            | A fine-tuned version of Llama 2 with a context window of 64k tokens.                                                                          |
| dolphin-phi-2.7b               | dolphin-phi-2.7b               | /v1/chat/completions            | False   | 500            | A 2.7B parameter model based on the Phi architecture.                                                                                       |
| merlinite-7b                   | merlinite-7b                   | /v1/chat/completions            | False   | 500            | A 7B parameter model trained on a massive dataset of text and code.                                                                           |
| magicoder-7b                   | magicoder-7b                   | /v1/chat/completions            | False   | 500            | A 7B parameter model trained for code generation.                                                                                             |
| phind-codellama-34b-v2         | phind-codellama-34b-v2         | /v1/chat/completions            | False   | 500            | An updated version of the Phind CodeLlama 34B model.                                                                                         |
| dolphin-phi-2.7b-v2.6          | dolphin-phi-2.7b-v2.6          | /v1/chat/completions            | False   | 500            | An updated version of the Dolphin Phi 2.7B model.                                                                                           |
| neural-chat-7b-v3.2            | neural-chat-7b-v3.2            | /v1/chat/completions            | False   | 500            | An updated version of the Neural Chat 7B model.                                                                                             |
| wizard-vicuna-uncensored-30b   | wizard-vicuna-uncensored-30b   | /v1/chat/completions            | False   | 500            | An uncensored version of the Wizard Vicuna 30B model.                                                                                        |
| dolphin-mistral-v2.1           | dolphin-mistral-v2.1           | /v1/chat/completions            | False   | 500            | A fine-tuned version of Mistral based on the Dolphin architecture.                                                                           |
| phi-2-super                    | phi-2-super                    | /v1/chat/completions            | False   | 500            | A powerful model based on the Phi architecture.                                                                                              |
| gorilla-openfunctions-v1       | gorilla-openfunctions-v1       | /v1/chat/completions            | False   | 500            | An updated version of the Gorilla OpenFunctions model.                                                                                        |
| phi-2.7b                       | phi-2.7b                       | /v1/chat/completions            | False   | 500            | A 2.7B parameter model based on the Phi architecture.                                                                                       |
| codeup-70b                     | codeup-70b                     | /v1/chat/completions            | False   | 500            | A 70B parameter model trained on a large dataset of code.                                                                                    |
| claude-1.2                     | claude-1.2                     | /v1/chat/completions            | False   | 500            | A previous version of the Claude model.                                                                                                        |
| openchat-7b                    | openchat-7b                    | /v1/chat/completions            | False   | 500            | A 7B parameter model trained for conversation.                                                                                                |
| labradorite-7b                  | labradorite-7b                  | /v1/chat/completions            | False   | 500            | A 7B parameter model trained on a massive dataset of text and code.                                                                           |
| internlm2-math-20b             | internlm2-math-20b             | /v1/chat/completions            | False   | 500            | A 20B parameter model trained for mathematical reasoning.                                                                                   |
| codebooga-34b-v0.1             | codebooga-34b-v0.1             | /v1/chat/completions            | False   | 500            | A 34B parameter model trained for code generation.                                                                                             |
| claude-instant-v1-100k         | claude-instant-v1-100k         | /v1/chat/completions            | False   | 500            | A version of Claude Instant with a context window of 100k tokens.                                                                            |
| giraffe-v2-70b-32k             | giraffe-v2-70b-32k             | /v1/chat/completions            | False   | 500            | A 70B parameter model with a context window of 32k tokens.                                                                                    |
| sonar-medium                   | sonar-medium                   | /v1/chat/completions            | False   | 500            | A model designed for code generation.                                                                                                         |
| dolphin-mistral-v2.6           | dolphin-mistral-v2.6           | /v1/chat/completions            | False   | 500            | A fine-tuned version of Mistral based on the Dolphin architecture.                                                                           |
| vicuna-7b                      | vicuna-7b                      | /v1/chat/completions            | False   | 500            | A 7B parameter model trained for conversation.                                                                                                |
| codellama-13b-instruct         | codellama-13b-instruct         | /v1/chat/completions            | False   | 500            | A 13B parameter model trained for code generation.                                                                                             |
| openhermes-7b-v2               | openhermes-7b-v2               | /v1/chat/completions            | False   | 500            | An updated version of the OpenHermes 7B model.                                                                                                |
| text-curie-001                 | text-curie-001                 | /v1/chat/completions            | False   | 500            | A smaller and faster model compared to Davinci.                                                                                               |
| toppy-7b                       | toppy-7b                       | /v1/chat/completions            | False   | 500            | A 7B parameter model trained for conversation.                                                                                                |
| nexusraven-13b-v2              | nexusraven-13b-v2              | /v1/chat/completions            | False   | 500            | An updated version of the NexusRaven 13B model.                                                                                              |
| yarn-mistral-64k                | yarn-mistral-64k                | /v1/chat/completions            | False   | 500            | A fine-tuned version of Mistral with a context window of 64k tokens.                                                                          |
| llamaguard-7b                  | llamaguard-7b                  | /v1/chat/completions            | False   | 500            | A 7B parameter model designed for safety and harmlessness.                                                                                   |
| xwinlm-7b-v0.2                 | xwinlm-7b-v0.2                 | /v1/chat/completions            | False   | 500            | A 7B parameter model from the XWinLM family.                                                                                                  |
| yarn-llama2-13b-64k            | yarn-llama2-13b-64k            | /v1/chat/completions            | False   | 500            | A fine-tuned version of Llama 2 with a context window of 64k tokens.                                                                          |
| starcoder2-3b                  | starcoder2-3b                  | /v1/chat/completions            | False   | 500            | A 3B parameter model from the StarCoder family.                                                                                                |
| experiment26-7B                | experiment26-7B                | /v1/chat/completions            | False   | 500            | A 7B parameter experimental model.                                                                                                           |
| duckdb-nsql-7b-q2_k            | duckdb-nsql-7b-q2_k            | /v1/chat/completions            | False   | 500            | A model specializing in natural language queries for DuckDB.                                                                                   |
| vicuna-33b                     | vicuna-33b                     | /v1/chat/completions            | False   | 500            | A 33B parameter model trained for conversation.                                                                                                |
| vicuna-33b-16k                 | vicuna-33b-16k                 | /v1/chat/completions            | False   | 500            | A 33B parameter model with a context window of 16k tokens.                                                                                   |
| gpt-4-1106-preview            | gpt-4-1106-preview            | /v1/chat/completions            | False   | 500            | A preview version of the GPT-4 model.                                                                                                         |
| qwen-14b                       | qwen-14b                       | /v1/chat/completions            | False   | 500            | A 14B parameter model from the Qwen family.                                                                                                   |
| liberated-qwen1.5-72b          | liberated-qwen1.5-72b          | /v1/chat/completions            | False   | 500            | A 72B parameter model from the Qwen family.                                                                                                   |
| neural-chat-7b-v3.1            | neural-chat-7b-v3.1            | /v1/chat/completions            | False   | 500            | An updated version of the Neural Chat 7B model.                                                                                             |
| medllama2-7b                   | medllama2-7b                   | /v1/chat/completions            | False   | 500            | A 7B parameter model trained on medical data.                                                                                                |
| gpt-3.5-turbo-0601             | gpt-3.5-turbo-0601             | /v1/chat/completions            | False   | 500            | A previous version of the GPT-3.5-turbo model.                                                                                              |
| mobillama-0.5b                 | mobillama-0.5b                 | /v1/chat/completions            | False   | 500            | A smaller and faster model designed for mobile devices.                                                                                    |
| mistral-next                   | mistral-next                   | /v1/chat/completions            | False   | 500            | A next-generation model from the Mistral family.                                                                                             |
| smaug-14b-v0.1                 | smaug-14b-v0.1                 | /v1/chat/completions            | False   | 500            | A 14B parameter model from the Smaug family.                                                                                                 |
| openhermes-7b-mistral          | openhermes-7b-mistral          | /v1/chat/completions            | False   | 500            | A fine-tuned version of OpenHermes 7B based on Mistral.                                                                                       |
| dolphin-mixtral-v2.6           | dolphin-mixtral-v2.6           | /v1/chat/completions            | False   | 500            | A fine-tuned version of Mixtral based on the Dolphin architecture.                                                                             |
| dolphin-mistral-v2             | dolphin-mistral-v2             | /v1/chat/completions            | False   | 500            | A fine-tuned version of Mistral based on the Dolphin architecture.                                                                           |
| zephyr-7b-alpha                | zephyr-7b-alpha                | /v1/chat/completions            | False   | 500            | A 7B parameter model from the Zephyr family.                                                                                                 |
| mistral-7b-instruct           | mistral-7b-instruct           | /v1/chat/completions            | False   | 500            | A version of Mistral 7B fine-tuned for following instructions.                                                                               |
| gorilla-openfunctions-v2       | gorilla-openfunctions-v2       | /v1/chat/completions            | False   | 500            | An updated version of the Gorilla OpenFunctions model.                                                                                        |
| gorilla-openfunctions-v1-mpt    | gorilla-openfunctions-v1-mpt    | /v1/chat/completions            | False   | 500            | A version of Gorilla OpenFunctions v1 using the MPT (Mosaic Pretrained Transformer) architecture.                                             |
| starcoder2-15b                  | starcoder2-15b                  | /v1/chat/completions            | False   | 500            | A 15B parameter model from the StarCoder family.                                                                                                |
| stable-code-3b                 | stable-code-3b                 | /v1/chat/completions            | False   | 500            | A 3B parameter model trained for code generation.                                                                                             |
| gorilla-openfunctions-v0-mpt    | gorilla-openfunctions-v0-mpt    | /v1/chat/completions            | False   | 500            | A version of Gorilla OpenFunctions v0 using the MPT (Mosaic Pretrained Transformer) architecture.                                             |
| tinydolphin-1.1b               | tinydolphin-1.1b               | /v1/chat/completions            | False   | 500            | A smaller and faster model designed for limited resources.                                                                                  |
| TinyMistral-248M-v2            | TinyMistral-248M-v2            | /v1/chat/completions            | False   | 500            | A smaller and faster version of Mistral.                                                                                                       |
| codeup-7b                      | codeup-7b                      | /v1/chat/completions            | False   | 500            | A 7B parameter model trained on a large dataset of code.                                                                                    |
| zephyr-alpha-7b                | zephyr-alpha-7b                | /v1/chat/completions            | False   | 500            | A 7B parameter model from the Zephyr family.                                                                                                 |
| sqlcoder-70b                   | sqlcoder-70b                   | /v1/chat/completions            | False   | 500            | A 70B parameter model trained for SQL code generation.                                                                                       |
| mistral-openorca-7b            | mistral-openorca-7b            | /v1/chat/completions            | False   | 500            | A fine-tuned version of Mistral based on the OpenOrca architecture.                                                                           |
| cinematika-7b                  | cinematika-7b                  | /v1/chat/completions            | False   | 500            | A 7B parameter model designed for creative writing and storytelling.                                                                          |
| discolm-7b                     | discolm-7b                     | /v1/chat/completions            | False   | 500            | A 7B parameter model trained on a large dataset of dialogue.                                                                                  |
| merlinite-13b                  | merlinite-13b                  | /v1/chat/completions            | False   | 500            | A 13B parameter model trained on a massive dataset of text and code.                                                                           |
| starcoder-3b                   | starcoder-3b                   | /v1/chat/completions            | False   | 500            | A 3B parameter model from the StarCoder family.                                                                                                |
| gpt-3.5-turbo-16k-0613         | gpt-3.5-turbo-16k-0613         | /v1/chat/completions            | False   | 500            | A version of GPT-3.5-turbo with a context window of 16k tokens.                                                                                |
| internlm2-chat-7b              | internlm2-chat-7b              | /v1/chat/completions            | False   | 500            | A 7B parameter model trained for conversation.                                                                                                |
| llava-13b                      | llava-13b                      | /v1/chat/completions            | False   | 500            | A 13B parameter model from the LLaVA family.                                                                                                  |
| Magicoder-S-DS-6.7B            | Magicoder-S-DS-6.7B            | /v1/chat/completions            | False   | 500            | A 6.7B parameter model trained for code generation.                                                                                             |
| gemma-7b                       | gemma-7b                       | /v1/chat/completions            | False   | 500            | A 7B parameter model trained on a large dataset of text and code.                                                                           |
| xwinlm-7b-v0.1                 | xwinlm-7b-v0.1                 | /v1/chat/completions            | False   | 500            | A 7B parameter model from the XWinLM family.                                                                                                  |
| nexusraven-13b                 | nexusraven-13b                 | /v1/chat/completions            | False   | 500            | A 13B parameter model from the NexusRaven family.                                                                                              |
| stable-beluga-70b              | stable-beluga-70b              | /v1/chat/completions            | False   | 500            | A 70B parameter model known for its stability and performance.                                                                                |
| qwen-7b                        | qwen-7b                        | /v1/chat/completions            | False   | 500            | A 7B parameter model from the Qwen family.                                                                                                   |
| dolphin-mixtral-v2.5           | dolphin-mixtral-v2.5           | /v1/chat/completions            | False   | 500            | A fine-tuned version of Mixtral based on the Dolphin architecture.                                                                             |
| gpt-3.5-turbo-0613             | gpt-3.5-turbo-0613             | /v1/chat/completions            | False   | 500            | A previous version of the GPT-3.5-turbo model.                                                                                              |
| everythinglm-7b-16k            | everythinglm-7b-16k            | /v1/chat/completions            | False   | 500            | A 7B parameter model with a context window of 16k tokens.                                                                                    |
| nous-hermes-34b                | nous-hermes-34b                | /v1/chat/completions            | False   | 500            | A 34B parameter model from the Nous Hermes family.                                                                                           |
| falcon-180b-chat               | falcon-180b-chat               | /v1/chat/completions            | False   | 500            | A 180B parameter model trained for conversation.                                                                                               |
| gpt-4-32k-0613                 | gpt-4-32k-0613                 | /v1/chat/completions            | False   | 500            | A version of GPT-4 with a context window of 32k tokens.                                                                                       |
| gpt-3.5-turbo-16k              | gpt-3.5-turbo-16k              | /v1/chat/completions            | False   | 500            | A version of GPT-3.5-turbo with a context window of 16k tokens.                                                                                |
| claude-instant-v1              | claude-instant-v1              | /v1/chat/completions            | False   | 500            | A fast and efficient version of the Claude model.                                                                                             |
| mythomist-7b                   | mythomist-7b                   | /v1/chat/completions            | False   | 500            | A 7B parameter model designed for creative writing and storytelling.                                                                          |
| everythinglm-70b               | everythinglm-70b               | /v1/chat/completions            | False   | 500            | A 70B parameter model trained on a large dataset of text and code.                                                                           |
| gpt-4-0125-preview            | gpt-4-0125-preview            | /v1/chat/completions            | False   | 500            | A preview version of the GPT-4 model.                                                                                                         |
| gpt-4-32k-0314                 | gpt-4-32k-0314                 | /v1/chat/completions            | False   | 500            | A version of GPT-4 with a context window of 32k tokens.                                                                                       |
| synapsellm-v0.9-preview        | synapsellm-v0.9-preview        | /v1/chat/completions            | False   | 500            | A preview version of the SynapseLLM model.                                                                                                   |
| llama2-7b                      | llama2-7b                      | /v1/chat/completions            | False   | 500            | A 7B parameter model from the Llama 2 family.                                                                                                 |
| tinyllama-1.1b-v1              | tinyllama-1.1b-v1              | /v1/chat/completions            | False   | 500            | A smaller and faster version of Llama 2.                                                                                                       |
| dolphin-mistral-v2.2           | dolphin-mistral-v2.2           | /v1/chat/completions            | False   | 500            | A fine-tuned version of Mistral based on the Dolphin architecture.                                                                           |
| stablelm-zephyr-3b              | stablelm-zephyr-3b              | /v1/chat/completions            | False   | 500            | A 3B parameter model from the StableLM Zephyr family.                                                                                          |
| mistral-tiny                   | mistral-tiny                   | /v1/chat/completions            | False   | 500            | A smaller and faster version of Mistral.                                                                                                       |
| liberated-qwen1.5-14b          | liberated-qwen1.5-14b          | /v1/chat/completions            | False   | 500            | A 14B parameter model from the Qwen family.                                                                                                   |
| mistral-large                  | mistral-large                  | /v1/chat/completions            | False   | 500            | A larger and more powerful version of Mistral.                                                                                               |
| everythinglm-70b-16k           | everythinglm-70b-16k           | /v1/chat/completions            | False   | 500            | A 70B parameter model with a context window of 16k tokens.                                                                                    |
| wizardmath-7b                  | wizardmath-7b                  | /v1/chat/completions            | False   | 500            | A 7B parameter model trained for mathematical reasoning.                                                                                   |
| gpt-4-0314                    | gpt-4-0314                    | /v1/chat/completions            | False   | 500            | A previous version of the GPT-4 model.                                                                                                         |
| openchat-7b-v3.5-1210          | openchat-7b-v3.5-1210          | /v1/chat/completions            | False   | 500            | An updated version of the OpenChat 7B model.                                                                                                 |
| starcoder2-7b                  | starcoder2-7b                  | /v1/chat/completions            | False   | 500            | A 7B parameter model from the StarCoder family.                                                                                                |
| gpt-3.5-turbo-1106             | gpt-3.5-turbo-1106             | /v1/chat/completions            | False   | 500            | A previous version of the GPT-3.5-turbo model.                                                                                              |
| tinyllama-1.1b-v0.6            | tinyllama-1.1b-v0.6            | /v1/chat/completions            | False   | 500            | A smaller and faster version of Llama 2.                                                                                                       |
| alfred-40b                     | alfred-40b                     | /v1/chat/completions            | False   | 500            | A 40B parameter model trained on a large dataset of text and code.                                                                           |
| wizardmath-13b                 | wizardmath-13b                 | /v1/chat/completions            | False   | 500            | A 13B parameter model trained for mathematical reasoning.                                                                                   |
| llama2-uncensored-70b          | llama2-uncensored-70b          | /v1/chat/completions            | False   | 500            | An uncensored version of the Llama 2 70B model.                                                                                              |
| openhermes-7b-v2.5            | openhermes-7b-v2.5            | /v1/chat/completions            | False   | 500            | An updated version of the OpenHermes 7B model.                                                                                                |
| labradorite-13b                 | labradorite-13b                 | /v1/chat/completions            | False   | 500            | A 13B parameter model trained on a massive dataset of text and code.                                                                           |
| deepseek-coder-6.7b            | deepseek-coder-6.7b            | /v1/chat/completions            | False   | 500            | A 6.7B parameter model trained for code generation.                                                                                             |
| stable-beluga-7b              | stable-beluga-7b              | /v1/chat/completions            | False   | 500            | A 7B parameter model known for its stability and performance.                                                                                |
| wizardcoder-7b                 | wizardcoder-7b                 | /v1/chat/completions            | False   | 500            | A 7B parameter model trained for code generation.                                                                                             |
| xwinlm-13b-v0.1                | xwinlm-13b-v0.1                | /v1/chat/completions            | False   | 500            | A 13B parameter model from the XWinLM family.                                                                                                  |
| giraffe-v3-13b-32k             | giraffe-v3-13b-32k             | /v1/chat/completions            | False   | 500            | A 13B parameter model with a context window of 32k tokens.                                                                                    |
| OpenHercules-2.5-Mistral-7B    | OpenHercules-2.5-Mistral-7B    | /v1/chat/completions            | False   | 500            | A fine-tuned version of Mistral based on the OpenHercules architecture.                                                                      |
| xwinlm-70b-v0.2                | xwinlm-70b-v0.2                | /v1/chat/completions            | False   | 500            | A 70B parameter model from the XWinLM family.                                                                                                  |
| yi-6b-200k                     | yi-6b-200k                     | /v1/chat/completions            | False   | 500            | A 6B parameter model trained on a large dataset of text and code.                                                                           |
| bakllava-7b                    | bakllava-7b                    | /v1/chat/completions            | False   | 500            | A 7B parameter model trained on a large dataset of text and code.                                                                           |
| vicuna-13b-v1.5                | vicuna-13b-v1.5                | /v1/chat/completions            | False   | 500            | An updated version of the Vicuna 13B model.                                                                                                  |
| yarn-llama2-13b-128k           | yarn-llama2-13b-128k           | /v1/chat/completions            | False   | 500            | A fine-tuned version of Llama 2 with a context window of 128k tokens.                                                                         |
| llama2-chinese-7b              | llama2-chinese-7b              | /v1/chat/completions            | False   | 500            | A 7B parameter model trained for Chinese language processing.                                                                                 |
| vicuna-33b-v1.5-16k            | vicuna-33b-v1.5-16k            | /v1/chat/completions            | False   | 500            | An updated version of the Vicuna 33B model with a context window of 16k tokens.                                                               |
| tinyllama-1.1b                | tinyllama-1.1b                | /v1/chat/completions            | False   | 500            | A smaller and faster version of Llama 2.                                                                                                       |
| gemini-pro-vision             | gemini-pro-vision             | /v1/chat/completions            | False   | 500            | A model trained for visual understanding and reasoning.                                                                                      |
| solar-10.7b                    | solar-10.7b                    | /v1/chat/completions            | False   | 500            | A 10.7B parameter model trained on a large dataset of text and code.                                                                          |
| xwinlm-70b-v0.1                | xwinlm-70b-v0.1                | /v1/chat/completions            | False   | 500            | A 70B parameter model from the XWinLM family.                                                                                                  |
| qwen-0.5b                       | qwen-0.5b                       | /v1/chat/completions            | False   | 500            | A smaller and faster model from the Qwen family.                                                                                               |
| dolphin-mistral-v2.6-dpo-laser | dolphin-mistral-v2.6-dpo-laser | /v1/chat/completions            | False   | 500            | A fine-tuned version of Mistral based on the Dolphin architecture, trained with DPO (Direct Preference Optimization) and LASER (Language-Agnostic SEntence Representations). |
| notus-7b                       | notus-7b                       | /v1/chat/completions            | False   | 500            | A 7B parameter model trained for factual language understanding and generation.                                                                |
| falcon-7b                      | falcon-7b                      | /v1/chat/completions            | False   | 500            | A 7B parameter model from the Falcon family.                                                                                                 |
| metamath-bagel-34b-v0.2-c1500  | metamath-bagel-34b-v0.2-c1500  | /v1/chat/completions            | False   | 500            | A 34B parameter model trained for mathematical reasoning.                                                                                   |
| Hyperion-1.5-Mistral-7B         | Hyperion-1.5-Mistral-7B         | /v1/chat/completions            | False   | 500            | A fine-tuned version of Mistral based on the Hyperion architecture.                                                                         |
| samantha-mistral-7b            | samantha-mistral-7b            | /v1/chat/completions            | False   | 500            | A fine-tuned version of Mistral 7B.                                                                                                           |
| gpt-4-0613                    | gpt-4-0613                    | /v1/chat/completions            | False   | 500            | A previous version of the GPT-4 model.                                                                                                         |
| claude                         | claude                         | /v1/chat/completions            | False   | 500            | A large language model from Anthropic.                                                                                                          |
| qwen-1.8b                       | qwen-1.8b                       | /v1/chat/completions            | False   | 500            | A 1.8B parameter model from the Qwen family.                                                                                                  |
| internlm-xcomposer2-vl-7b       | internlm-xcomposer2-vl-7b       | /v1/chat/completions            | False   | 500            | A 7B parameter model trained for visual language understanding.                                                                                |
| wizardlm-13b                  | wizardlm-13b                  | /v1/chat/completions            | False   | 500            | A 13B parameter model trained for conversation and code generation.                                                                           |
| medllama2-13b                  | medllama2-13b                  | /v1/chat/completions            | False   | 500            | A 13B parameter model trained on medical data.                                                                                                |
| falcon-40b                     | falcon-40b                     | /v1/chat/completions            | False   | 500            | A 40B parameter model from the Falcon family.                                                                                                 |
| nous-hermes2-mixtral-8x7b-dpo   | nous-hermes2-mixtral-8x7b-dpo   | /v1/chat/completions            | False   | 500            | A model based on the Mixtral architecture, trained with DPO (Direct Preference Optimization).                                                 |
| gpt-3.5-turbo                  | gpt-3.5-turbo                  | /v1/chat/completions            | False   | 500            | A powerful and versatile large language model.                                                                                                |
| wizardcoder-13b                | wizardcoder-13b                | /v1/chat/completions            | False   | 500            | A 13B parameter model trained for code generation.                                                                                             |
| vicuna-13b-v1.5-16k            | vicuna-13b-v1.5-16k            | /v1/chat/completions            | False   | 500            | An updated version of the Vicuna 13B model with a context window of 16k tokens.                                                               |
| goliath-120b                  | goliath-120b                  | /v1/chat/completions            | False   | 500            | A 120B parameter model trained on a massive dataset of text and code.                                                                          |
| apt-4                         | apt-4                         | /v1/chat/completions            | False   | 500            | A 4th generation model from the Adept family.                                                                                                |
| starling-lm-7b                 | starling-lm-7b                 | /v1/chat/completions            | False   | 500            | A 7B parameter model trained for conversation and creative writing.                                                                           |
| vicuna-7b-v1.5-16k             | vicuna-7b-v1.5-16k             | /v1/chat/completions            | False   | 500            | An updated version of the Vicuna 7B model with a context window of 16k tokens.                                                                |
| vicuna-33b-v1.5                | vicuna-33b-v1.5                | /v1/chat/completions            | False   | 500            | An updated version of the Vicuna 33B model.                                                                                                  |
| claude-2                       | claude-2                       | /v1/chat/completions            | False   | 500            | An updated version of the Claude model.                                                                                                        |
| vicuna-7b-16k                  | vicuna-7b-16k                  | /v1/chat/completions            | False   | 500            | A 7B parameter model with a context window of 16k tokens.                                                                                    |
| gpt-4-vision-preview           | gpt-4-vision-preview           | /v1/chat/completions            | False   | 500            | A preview version of the GPT-4 model with vision capabilities.                                                                               |
| everythinglm-13b-16k           | everythinglm-13b-16k           | /v1/chat/completions            | False   | 500            | A 13B parameter model with a context window of 16k tokens.                                                                                    |
| vicuna-7b-v1.5                 | vicuna-7b-v1.5                 | /v1/chat/completions            | False   | 500            | An updated version of the Vicuna 7B model.                                                                                                  |
| gpt-3.5-turbo-instruct-0914     | gpt-3.5-turbo-instruct-0914     | /v1/chat/completions            | False   | 500            | A version of GPT-3.5-turbo fine-tuned for following instructions.                                                                             |
| palm-2                         | palm-2                         | /v1/chat/completions            | False   | 500            | A large language model from Google AI.                                                                                                         |
| text-davinci-003               | text-davinci-003               | /v1/chat/completions            | False   | 500            | A powerful and versatile large language model.                                                                                                |
| codellama-34b-instruct         | codellama-34b-instruct         | /v1/chat/completions            | False   | 500            | A 34B parameter model trained for code generation.                                                                                             |
| llama2-70b                     | llama2-70b                     | /v1/chat/completions            | False   | 500            | A 70B parameter model from the Llama 2 family.                                                                                                 |
| starcoder-1b                   | starcoder-1b                   | /v1/chat/completions            | False   | 500            | A 1B parameter model from the StarCoder family.                                                                                                |
| vicuna-13b                     | vicuna-13b                     | /v1/chat/completions            | False   | 500            | A 13B parameter model trained for conversation.                                                                                                |
| claude-2.1                     | claude-2.1                     | /v1/chat/completions            | False   | 500            | An updated version of the Claude model.                                                                                                        |
| mixtral-instruct               | mixtral-instruct               | /v1/chat/completions            | False   | 500            | A model based on the Mixtral architecture, fine-tuned for following instructions.                                                             |
| meditron-70b                   | meditron-70b                   | /v1/chat/completions            | False   | 500            | A 70B parameter model trained on medical data.                                                                                                |
| phind-codellama-34b            | phind-codellama-34b            | /v1/chat/completions            | False   | 500            | A 34B parameter model trained for code generation.                                                                                             |
| metamath-bagel-dpo-34b         | metamath-bagel-dpo-34b         | /v1/chat/completions            | False   | 500            | A 34B parameter model trained for mathematical reasoning, using DPO (Direct Preference Optimization).                                        |
| theprofessor-155b              | theprofessor-155b              | /v1/chat/completions            | False   | 500            | A 155B parameter model trained on a massive dataset of text and code.                                                                          |
| qwen-72b                       | qwen-72b                       | /v1/chat/completions            | False   | 500            | A 72B parameter model from the Qwen family.                                                                                                   |
| tinydolphin-1.1b-v2.8          | tinydolphin-1.1b-v2.8          | /v1/chat/completions            | False   | 500            | An updated version of the TinyDolphin 1.1B model.                                                                                            |
| deepseek-llm-67b               | deepseek-llm-67b               | /v1/chat/completions            | False   | 500            | A 67B parameter model trained on a large dataset of text and code.                                                                           |
| falcon-180b                    | falcon-180b                    | /v1/chat/completions            | False   | 500            | A 180B parameter model from the Falcon family.                                                                                                 |
| wizard-vicuna-uncensored-13b    | wizard-vicuna-uncensored-13b    | /v1/chat/completions            | False   | 500            | An uncensored version of the Wizard Vicuna 13B model.                                                                                        |
| internlm2-20b                  | internlm2-20b                  | /v1/chat/completions            | False   | 500            | A 20B parameter model from the InternLM2 family.                                                                                             |
| starcoder-7b                   | starcoder-7b                   | /v1/chat/completions            | False   | 500            | A 7B parameter model from the StarCoder family.                                                                                                |
| gemma-2b                       | gemma-2b                       | /v1/chat/completions            | False   | 500            | A 2B parameter model trained on a large dataset of text and code.                                                                           |
| mistral-medium                  | mistral-medium                  | /v1/chat/completions            | False   | 500            | A versatile and efficient model from the Mistral family.                                                                                    |
| llama2-uncensored-7b          | llama2-uncensored-7b          | /v1/chat/completions            | False   | 500            | An uncensored version of the Llama 2 7B model.                                                                                              |
| gpt-4-32k                     | gpt-4-32k                     | /v1/chat/completions            | False   | 500            | A version of GPT-4 with a context window of 32k tokens.                                                                                       |
| open-orca-platypus2-13b        | open-orca-platypus2-13b        | /v1/chat/completions            | False   | 500            | A 13B parameter model based on the OpenOrca and Platypus2 architectures.                                                                      |
| wizard-vicuna-uncensored-7b    | wizard-vicuna-uncensored-7b    | /v1/chat/completions            | False   | 500            | An uncensored version of the Wizard Vicuna 7B model.                                                                                        |
| sqlcoder-7b                   | sqlcoder-7b                   | /v1/chat/completions            | False   | 500            | A 7B parameter model trained for SQL code generation.                                                                                       |
| text-babbage-001               | text-babbage-001               | /v1/chat/completions            | False   | 500            | A smaller and faster model compared to Davinci.                                                                                               |
| dolphin-mixtral-v2.6.1         | dolphin-mixtral-v2.6.1         | /v1/chat/completions            | False   | 500            | An updated version of the Dolphin Mixtral v2.6 model.                                                                                        |
| sqlcoder-70b-alpha              | sqlcoder-70b-alpha              | /v1/chat/completions            | False   | 500            | An alpha version of the SQLCoder 70B model.                                                                                               |
| smaug-72b-v0.1                  | smaug-72b-v0.1                  | /v1/chat/completions            | False   | 500            | A 72B parameter model from the Smaug family.                                                                                                  |
| text-davinci-002                | text-davinci-002                | /v1/chat/completions            | False   | 500            | A previous version of the text-davinci model.                                                                                                |
| llama-pro-8b                    | llama-pro-8b                    | /v1/chat/completions            | False   | 500            | An 8B parameter model from the Llama Pro family.                                                                                             |
| openchat-7b-v3.5-0106           | openchat-7b-v3.5-0106           | /v1/chat/completions            | False   | 500            | An updated version of the OpenChat 7B model.                                                                                                 |
| structlm-34b                   | structlm-34b                   | /v1/chat/completions            | False   | 500            | A 34B parameter model designed for understanding and generating structured data.                                                             |
| mobillama-1b                   | mobillama-1b                   | /v1/chat/completions            | False   | 500            | A 1B parameter model designed for mobile devices.                                                                                           |
| llama2-13b                     | llama2-13b                     | /v1/chat/completions            | False   | 500            | A 13B parameter model from the Llama 2 family.                                                                                                 |
| 0dai-7B                        | 0dai-7B                        | /v1/chat/completions            | False   | 500            | A 7B parameter model trained on a large dataset of text and code.                                                                           |
| megadolphin-120b-v2.2           | megadolphin-120b-v2.2           | /v1/chat/completions            | False   | 500            | An updated version of the MegaDolphin 120B model.                                                                                          |
| magicoder-7b-s-cl              | magicoder-7b-s-cl              | /v1/chat/completions            | False   | 500            | A 7B parameter model trained for code generation.                                                                                             |
| sonar-small                    | sonar-small                    | /v1/chat/completions            | False   | 500            | A smaller and faster version of Sonar.                                                                                                     |
| starling-lm-7b-alpha            | starling-lm-7b-alpha            | /v1/chat/completions            | False   | 500            | An alpha version of the Starling-LM 7B model.                                                                                            |
| megadolphin-120b               | megadolphin-120b               | /v1/chat/completions            | False   | 500            | A 120B parameter model trained on a massive dataset of text and code.                                                                          |
| everythinglm-7b                | everythinglm-7b                | /v1/chat/completions            | False   | 500            | A 7B parameter model trained on a large dataset of text and code.                                                                           |
| deepseek-coder-33b             | deepseek-coder-33b             | /v1/chat/completions            | False   | 500            | A 33B parameter model trained for code generation.                                                                                             |
| mythomax-13b                   | mythomax-13b                   | /v1/chat/completions            | False   | 500            | A 13B parameter model designed for creative writing and storytelling.                                                                          |
| smaug-34b-v0.1                  | smaug-34b-v0.1                  | /v1/chat/completions            | False   | 500            | A 34B parameter model from the Smaug family.                                                                                                  |
| mobillama-0.8b                 | mobillama-0.8b                 | /v1/chat/completions            | False   | 500            | A smaller and faster model designed for mobile devices.                                                                                    |
| openchat-7b-v3.5               | openchat-7b-v3.5               | /v1/chat/completions            | False   | 500            | An updated version of the OpenChat 7B model.                                                                                                 |
| codellama-7b-instruct         | codellama-7b-instruct         | /v1/chat/completions            | False   | 500            | A 7B parameter model trained for code generation.                                                                                             |
| dolphin-2.2-7b                 | dolphin-2.2-7b                 | /v1/chat/completions            | False   | 500            | A 7B parameter model from the Dolphin family.                                                                                                 |
| stablelm-2-zephyr-1.6b          | stablelm-2-zephyr-1.6b          | /v1/chat/completions            | False   | 500            | A 1.6B parameter model from the StableLM Zephyr family.                                                                                          |
| wizardlm-7b                   | wizardlm-7b                   | /v1/chat/completions            | False   | 500            | A 7B parameter model trained for conversation and code generation.                                                                           |
| qwen-4b                        | qwen-4b                        | /v1/chat/completions            | False   | 500            | A 4B parameter model from the Qwen family.                                                                                                   |
| rocket-3b                      | rocket-3b                      | /v1/chat/completions            | False   | 500            | A 3B parameter model designed for code generation.                                                                                             |
| dolphin-mixtral-v2.7           | dolphin-mixtral-v2.7           | /v1/chat/completions            | False   | 500            | A fine-tuned version of Mixtral based on the Dolphin architecture.                                                                             |
| xwinlm-13b-v0.2                | xwinlm-13b-v0.2                | /v1/chat/completions            | False   | 500            | A 13B parameter model from the XWinLM family.                                                                                                  |
| notux-8x7b                     | notux-8x7b                     | /v1/chat/completions            | False   | 500            | An 8x7B parameter model trained for factual language understanding and generation.                                                             |
| mistrallite-7b-v0.1             | mistrallite-7b-v0.1             | /v1/chat/completions            | False   | 500            | A 7B parameter model from the MistralLite family.                                                                                            |
| yarn-mistral-128k               | yarn-mistral-128k               | /v1/chat/completions            | False   | 500            | A fine-tuned version of Mistral with a context window of 128k tokens.                                                                         |
| sailor-7B                      | sailor-7B                      | /v1/chat/completions            | False   | 500            | A 7B parameter model trained for conversation and creative writing.                                                                           |
| neural-chat-7b-v3.3            | neural-chat-7b-v3.3            | /v1/chat/completions            | False   | 500            | An updated version of the Neural Chat 7B model.                                                                                             |
| sqlcoder-15b                   | sqlcoder-15b                   | /v1/chat/completions            | False   | 500            | A 15B parameter model trained for SQL code generation.                                                                                       |
| starcoder-15b                  | starcoder-15b                  | /v1/chat/completions            | False   | 500            | A 15B parameter model from the StarCoder family.                                                                                                |
| claude-1-100k                  | claude-1-100k                  | /v1/chat/completions            | False   | 500            | A previous version of the Claude model with a context window of 100k tokens.                                                                  |
| text-ada-001                    | text-ada-001                    | /v1/chat/completions            | False   | 500            | A smaller and faster model compared to Babbage.                                                                                               |
| nous-hermes-10.7b               | nous-hermes-10.7b               | /v1/chat/completions            | False   | 500            | A 10.7B parameter model from the Nous Hermes family.                                                                                           |
| meditron-7b                    | meditron-7b                    | /v1/chat/completions            | False   | 500            | A 7B parameter model trained on medical data.                                                                                                |
| phi-2.7b-chat                  | phi-2.7b-chat                  | /v1/chat/completions            | False   | 500            | A 2.7B parameter model based on the Phi architecture, fine-tuned for conversation.                                                             |
| deepseek-llm-7b                | deepseek-llm-7b                | /v1/chat/completions            | False   | 500            | A 7B parameter model trained on a large dataset of text and code.                                                                           |
| codellama-7b-python           | codellama-7b-python           | /v1/chat/completions            | False   | 500            | A 7B parameter model trained for Python code generation.                                                                                    |
| codellama-34b-python           | codellama-34b-python           | /v1/chat/completions            | False   | 500            | A 34B parameter model trained for Python code generation.                                                                                    |
| internlm2-math-7b              | internlm2-math-7b              | /v1/chat/completions            | False   | 500            | A 7B parameter model trained for mathematical reasoning.                                                                                   |
| wizard-vicuna-13b               | wizard-vicuna-13b               | /v1/chat/completions            | False   | 500            | A 13B parameter model trained for conversation and code generation.                                                                           |
| yi-34b-200k                    | yi-34b-200k                    | /v1/chat/completions            | False   | 500            | A 34B parameter model trained on a large dataset of text and code.                                                                           |












