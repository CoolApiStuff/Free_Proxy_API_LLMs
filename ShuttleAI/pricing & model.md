<table>
  <tr>
   <td><strong>Free</strong>
   </td>
   <td><strong>ID</strong>
   </td>
   <td><strong>Name</strong>
   </td>
   <td><strong>Description</strong>
   </td>
   <td><strong>Owner</strong>
   </td>
   <td><strong>Cost/Req</strong>
   </td>
   <td><strong>Supports Tools</strong>
   </td>
   <td><strong>Max Input Tokens</strong>
   </td>
   <td><strong>Max Output Tokens</strong>
   </td>
   <td><strong>Supports Image Input</strong>
   </td>
   <td><strong>Supports Audio Input</strong>
   </td>
   <td><strong>Endpoint</strong>
   </td>
  </tr>
  <tr>
   <td>‚úîÔ∏è
   </td>
   <td>shuttle-2-turbo
   </td>
   <td>Shuttle Turbo (64k)
   </td>
   <td>ShuttleAI‚Äôs largest LLM, updated mid 2024. Shuttle-2-turbo is comparable to GPT-4-1106-preview, and significantly stronger than GPT-4-0314. It demonstrates highly competitive performance and consistently outperforms all the existing state-of-the-art opensource models.
   </td>
   <td>shuttleai
   </td>
   <td>1
   </td>
   <td>Yes
   </td>
   <td>65536
   </td>
   <td>4096
   </td>
   <td>Yes
   </td>
   <td>No
   </td>
   <td>/v1/chat/completions
   </td>
  </tr>
  <tr>
   <td>‚úîÔ∏è
   </td>
   <td>shuttle-turbo
   </td>
   <td>Shuttle Turbo (32k)
   </td>
   <td>ShuttleAI‚Äôs first turbo chat completion model with built in support for image recognition & web access released on February 17th, 2024.
   </td>
   <td>shuttleai
   </td>
   <td>1
   </td>
   <td>No
   </td>
   <td>32768
   </td>
   <td>4096
   </td>
   <td>Yes
   </td>
   <td>No
   </td>
   <td>/v1/chat/completions
   </td>
  </tr>
  <tr>
   <td>üí∞
   </td>
   <td>gpt-4o-2024-05-13
   </td>
   <td>GPT-4 Omni
   </td>
   <td>OpenAI‚Äôs latest flagship model. Cheaper, faster, and smarter than GPT-4 Turbo.
   </td>
   <td>openai
   </td>
   <td>4
   </td>
   <td>No
   </td>
   <td>128000
   </td>
   <td>4096
   </td>
   <td>Yes
   </td>
   <td>Yes
   </td>
   <td>/v1/chat/completions
   </td>
  </tr>
  <tr>
   <td>üí∞
   </td>
   <td>gpt-4o-2024-05-13
   </td>
   <td>GPT-4 Omni
   </td>
   <td>OpenAI‚Äôs latest flagship model. Cheaper, faster, and smarter than GPT-4 Turbo.
   </td>
   <td>openai
   </td>
   <td>4
   </td>
   <td>No
   </td>
   <td>128000
   </td>
   <td>4096
   </td>
   <td>Yes
   </td>
   <td>Yes
   </td>
   <td>/v1/chat/completions
   </td>
  </tr>
  <tr>
   <td>üí∞
   </td>
   <td>gpt-4o-2024-05-13
   </td>
   <td>GPT-4 Omni
   </td>
   <td>OpenAI‚Äôs latest flagship model. Cheaper, faster, and smarter than GPT-4 Turbo.
   </td>
   <td>openai
   </td>
   <td>4
   </td>
   <td>No
   </td>
   <td>128000
   </td>
   <td>4096
   </td>
   <td>Yes
   </td>
   <td>Yes
   </td>
   <td>/v1/chat/completions
   </td>
  </tr>
  <tr>
   <td>üí∞
   </td>
   <td>gpt-4-turbo-2024-04-09
   </td>
   <td>GPT 4 Turbo
   </td>
   <td>The latest GPT-4 Turbo model with vision capabilities. Vision requests can now use JSON mode and function calling.
   </td>
   <td>openai
   </td>
   <td>4
   </td>
   <td>Yes
   </td>
   <td>128000
   </td>
   <td>4096
   </td>
   <td>Yes
   </td>
   <td>No
   </td>
   <td>/v1/chat/completions
   </td>
  </tr>
  <tr>
   <td>üí∞
   </td>
   <td>gpt-4-turbo-2024-04-09
   </td>
   <td>GPT 4 Turbo
   </td>
   <td>The latest GPT-4 Turbo model with vision capabilities. Vision requests can now use JSON mode and function calling.
   </td>
   <td>openai
   </td>
   <td>4
   </td>
   <td>Yes
   </td>
   <td>128000
   </td>
   <td>4096
   </td>
   <td>Yes
   </td>
   <td>No
   </td>
   <td>/v1/chat/completions
   </td>
  </tr>
  <tr>
   <td>üí∞
   </td>
   <td>gpt-4-0125-preview
   </td>
   <td>GPT 4 Turbo Preview (0125)
   </td>
   <td>GPT-4 Turbo preview model intended to reduce cases of ‚Äúlaziness‚Äù where the model doesn‚Äôt complete a task.
   </td>
   <td>openai
   </td>
   <td>4
   </td>
   <td>Yes
   </td>
   <td>128000
   </td>
   <td>4096
   </td>
   <td>No
   </td>
   <td>No
   </td>
   <td>/v1/chat/completions
   </td>
  </tr>
  <tr>
   <td>üí∞
   </td>
   <td>gpt-4-0125-preview
   </td>
   <td>GPT 4 Turbo Preview (0125)
   </td>
   <td>GPT-4 Turbo preview model intended to reduce cases of ‚Äúlaziness‚Äù where the model doesn‚Äôt complete a task.
   </td>
   <td>openai
   </td>
   <td>4
   </td>
   <td>Yes
   </td>
   <td>128000
   </td>
   <td>4096
   </td>
   <td>No
   </td>
   <td>No
   </td>
   <td>/v1/chat/completions
   </td>
  </tr>
  <tr>
   <td>üí∞
   </td>
   <td>gpt-4-1106-preview
   </td>
   <td>GPT 4 Turbo Preview (1106)
   </td>
   <td>GPT-4 Turbo preview model featuring improved instruction following, JSON mode, reproducible outputs, parallel function calling, and more.
   </td>
   <td>openai
   </td>
   <td>4
   </td>
   <td>Yes
   </td>
   <td>128000
   </td>
   <td>4096
   </td>
   <td>No
   </td>
   <td>No
   </td>
   <td>/v1/chat/completions
   </td>
  </tr>
  <tr>
   <td>üí∞
   </td>
   <td>gpt-4-1106-vision-preview
   </td>
   <td>GPT 4 Vision Preview (1106)
   </td>
   <td>GPT-4 model with the ability to understand images, in addition to all other GPT-4 Turbo capabilities. This is a preview model, we recommend developers to now use gpt-4-turbo which includes vision capabilities.
   </td>
   <td>openai
   </td>
   <td>4
   </td>
   <td>No
   </td>
   <td>128000
   </td>
   <td>4096
   </td>
   <td>Yes
   </td>
   <td>No
   </td>
   <td>/v1/chat/completions
   </td>
  </tr>
  <tr>
   <td>üí∞
   </td>
   <td>gpt-4-1106-vision-preview
   </td>
   <td>GPT 4 Vision Preview (1106)
   </td>
   <td>GPT-4 model with the ability to understand images, in addition to all other GPT-4 Turbo capabilities. This is a preview model, we recommend developers to now use gpt-4-turbo which includes vision capabilities.
   </td>
   <td>openai
   </td>
   <td>4
   </td>
   <td>No
   </td>
   <td>128000
   </td>
   <td>4096
   </td>
   <td>Yes
   </td>
   <td>No
   </td>
   <td>/v1/chat/completions
   </td>
  </tr>
  <tr>
   <td>‚úîÔ∏è
   </td>
   <td>gpt-4-0613
   </td>
   <td>GPT 4 (0613)
   </td>
   <td>Snapshot of gpt-4 from June 13th 2023 with improved function calling support.
   </td>
   <td>openai
   </td>
   <td>2
   </td>
   <td>Yes
   </td>
   <td>8192
   </td>
   <td>4096
   </td>
   <td>No
   </td>
   <td>No
   </td>
   <td>/v1/chat/completions
   </td>
  </tr>
  <tr>
   <td>‚úîÔ∏è
   </td>
   <td>gpt-4-0613
   </td>
   <td>GPT 4 (0613)
   </td>
   <td>Snapshot of gpt-4 from June 13th 2023 with improved function calling support.
   </td>
   <td>openai
   </td>
   <td>2
   </td>
   <td>Yes
   </td>
   <td>8192
   </td>
   <td>4096
   </td>
   <td>No
   </td>
   <td>No
   </td>
   <td>/v1/chat/completions
   </td>
  </tr>
  <tr>
   <td>‚úîÔ∏è
   </td>
   <td>gpt-4-bing
   </td>
   <td>GPT 4 (Bing)
   </td>
   <td>GPT-4 model with improved instruction following, and web search provided by Bing.
   </td>
   <td>bing
   </td>
   <td>1
   </td>
   <td>No
   </td>
   <td>29000
   </td>
   <td>4000
   </td>
   <td>Yes
   </td>
   <td>No
   </td>
   <td>/v1/chat/completions
   </td>
  </tr>
  <tr>
   <td>‚úîÔ∏è
   </td>
   <td>gpt-4-turbo-bing
   </td>
   <td>GPT 4 Turbo (Bing)
   </td>
   <td>Faster GPT-4-Turbo model with improved instruction following, and fast web search provided by Bing.
   </td>
   <td>bing
   </td>
   <td>2
   </td>
   <td>No
   </td>
   <td>32000
   </td>
   <td>4000
   </td>
   <td>Yes
   </td>
   <td>No
   </td>
   <td>/v1/chat/completions
   </td>
  </tr>
  <tr>
   <td>üí∞
   </td>
   <td>gpt-4-32k-0613
   </td>
   <td>GPT 4 32k (0613)
   </td>
   <td>Snapshot of gpt-4-32k from June 13th 2023 with improved function calling support. This model was never rolled out widely in favor of GPT-4 Turbo.
   </td>
   <td>openai
   </td>
   <td>3
   </td>
   <td>No
   </td>
   <td>32768
   </td>
   <td>4096
   </td>
   <td>No
   </td>
   <td>No
   </td>
   <td>/v1/chat/completions
   </td>
  </tr>
  <tr>
   <td>üí∞
   </td>
   <td>gpt-4-32k-0613
   </td>
   <td>GPT 4 32k (0613)
   </td>
   <td>Snapshot of gpt-4-32k from June 13th 2023 with improved function calling support. This model was never rolled out widely in favor of GPT-4 Turbo.
   </td>
   <td>openai
   </td>
   <td>3
   </td>
   <td>No
   </td>
   <td>32768
   </td>
   <td>4096
   </td>
   <td>No
   </td>
   <td>No
   </td>
   <td>/v1/chat/completions
   </td>
  </tr>
  <tr>
   <td>‚úîÔ∏è
   </td>
   <td>gpt-3.5-turbo-0125
   </td>
   <td>GPT 3.5 Turbo (0125)
   </td>
   <td>The latest GPT-3.5 Turbo model with higher accuracy at responding in requested formats and a fix for a bug which caused a text encoding issue for non-English language function calls.
   </td>
   <td>openai
   </td>
   <td>2
   </td>
   <td>Yes
   </td>
   <td>16385
   </td>
   <td>4096
   </td>
   <td>No
   </td>
   <td>No
   </td>
   <td>/v1/chat/completions
   </td>
  </tr>
  <tr>
   <td>‚úîÔ∏è
   </td>
   <td>gpt-3.5-turbo-0125
   </td>
   <td>GPT 3.5 Turbo (0125)
   </td>
   <td>The latest GPT-3.5 Turbo model with higher accuracy at responding in requested formats and a fix for a bug which caused a text encoding issue for non-English language function calls.
   </td>
   <td>openai
   </td>
   <td>2
   </td>
   <td>Yes
   </td>
   <td>16385
   </td>
   <td>4096
   </td>
   <td>No
   </td>
   <td>No
   </td>
   <td>/v1/chat/completions
   </td>
  </tr>
  <tr>
   <td>‚úîÔ∏è
   </td>
   <td>gpt-3.5-turbo-1106
   </td>
   <td>GPT 3.5 Turbo (1106)
   </td>
   <td>GPT-3.5 Turbo model with improved instruction following, JSON mode, reproducible outputs, parallel function calling, and more.
   </td>
   <td>openai
   </td>
   <td>2
   </td>
   <td>Yes
   </td>
   <td>16385
   </td>
   <td>4096
   </td>
   <td>No
   </td>
   <td>No
   </td>
   <td>/v1/chat/completions
   </td>
  </tr>
  <tr>
   <td>üí∞
   </td>
   <td>claude-3-opus-20240229
   </td>
   <td>Claude 3 Opus
   </td>
   <td>Most powerful model for highly complex tasks.
   </td>
   <td>anthropic
   </td>
   <td>9
   </td>
   <td>No
   </td>
   <td>200000
   </td>
   <td>4096
   </td>
   <td>Yes
   </td>
   <td>No
   </td>
   <td>/v1/chat/completions
   </td>
  </tr>
  <tr>
   <td>üí∞
   </td>
   <td>claude-3-opus-20240229
   </td>
   <td>Claude 3 Opus
   </td>
   <td>Most powerful model for highly complex tasks.
   </td>
   <td>anthropic
   </td>
   <td>9
   </td>
   <td>No
   </td>
   <td>200000
   </td>
   <td>4096
   </td>
   <td>Yes
   </td>
   <td>No
   </td>
   <td>/v1/chat/completions
   </td>
  </tr>
  <tr>
   <td>üí∞
   </td>
   <td>claude-3-sonnet-20240229
   </td>
   <td>Claude 3 Sonnet
   </td>
   <td>Ideal balance of intelligence and speed for enterprise workloads.
   </td>
   <td>anthropic
   </td>
   <td>7
   </td>
   <td>No
   </td>
   <td>200000
   </td>
   <td>4096
   </td>
   <td>Yes
   </td>
   <td>No
   </td>
   <td>/v1/chat/completions
   </td>
  </tr>
  <tr>
   <td>üí∞
   </td>
   <td>claude-3-sonnet-20240229
   </td>
   <td>Claude 3 Sonnet
   </td>
   <td>Ideal balance of intelligence and speed for enterprise workloads.
   </td>
   <td>anthropic
   </td>
   <td>7
   </td>
   <td>No
   </td>
   <td>200000
   </td>
   <td>4096
   </td>
   <td>Yes
   </td>
   <td>No
   </td>
   <td>/v1/chat/completions
   </td>
  </tr>
  <tr>
   <td>üí∞
   </td>
   <td>claude-3-haiku-20240307
   </td>
   <td>Claude 3 Haiku
   </td>
   <td>Fastest and most compact model for near-instant responsiveness.
   </td>
   <td>anthropic
   </td>
   <td>3
   </td>
   <td>No
   </td>
   <td>200000
   </td>
   <td>4096
   </td>
   <td>Yes
   </td>
   <td>No
   </td>
   <td>/v1/chat/completions
   </td>
  </tr>
  <tr>
   <td>üí∞
   </td>
   <td>claude-3-haiku-20240307
   </td>
   <td>Claude 3 Haiku
   </td>
   <td>Fastest and most compact model for near-instant responsiveness.
   </td>
   <td>anthropic
   </td>
   <td>3
   </td>
   <td>No
   </td>
   <td>200000
   </td>
   <td>4096
   </td>
   <td>Yes
   </td>
   <td>No
   </td>
   <td>/v1/chat/completions
   </td>
  </tr>
  <tr>
   <td>üí∞
   </td>
   <td>claude-2.1
   </td>
   <td>Claude 2.1
   </td>
   <td>Updated version of Claude 2 with improved accuracy.
   </td>
   <td>anthropic
   </td>
   <td>7
   </td>
   <td>No
   </td>
   <td>200000
   </td>
   <td>4096
   </td>
   <td>No
   </td>
   <td>No
   </td>
   <td>/v1/chat/completions
   </td>
  </tr>
  <tr>
   <td>üí∞
   </td>
   <td>claude-2.0
   </td>
   <td>Claude 2
   </td>
   <td>Predecessor to Claude 3, offering strong all-round performance.
   </td>
   <td>anthropic
   </td>
   <td>6
   </td>
   <td>No
   </td>
   <td>100000
   </td>
   <td>4096
   </td>
   <td>No
   </td>
   <td>No
   </td>
   <td>/v1/chat/completions
   </td>
  </tr>
  <tr>
   <td>üí∞
   </td>
   <td>claude-2.0
   </td>
   <td>Claude 2
   </td>
   <td>Predecessor to Claude 3, offering strong all-round performance.
   </td>
   <td>anthropic
   </td>
   <td>6
   </td>
   <td>No
   </td>
   <td>100000
   </td>
   <td>4096
   </td>
   <td>No
   </td>
   <td>No
   </td>
   <td>/v1/chat/completions
   </td>
  </tr>
  <tr>
   <td>üí∞
   </td>
   <td>claude-instant-1.2
   </td>
   <td>Claude Instant v1.2
   </td>
   <td>Anthhropic‚Äôs small and fast model, a predecessor of Claude Haiku.
   </td>
   <td>anthropic
   </td>
   <td>3
   </td>
   <td>No
   </td>
   <td>100000
   </td>
   <td>4096
   </td>
   <td>No
   </td>
   <td>No
   </td>
   <td>/v1/chat/completions
   </td>
  </tr>
  <tr>
   <td>üí∞
   </td>
   <td>claude-instant-1.1
   </td>
   <td>Claude Instant v1.1
   </td>
   <td>Anthhropic‚Äôs small and fast model, a predecessor of Claude Haiku.
   </td>
   <td>anthropic
   </td>
   <td>2
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>/v1/chat/completions
   </td>
  </tr>
  <tr>
   <td>‚úîÔ∏è
   </td>
   <td>claude-instant-1.0
   </td>
   <td>Claude Instant v1.0
   </td>
   <td>Anthhropic‚Äôs small and fast model, a predecessor of Claude Haiku.
   </td>
   <td>anthropic
   </td>
   <td>2
   </td>
   <td>No
   </td>
   <td>100000
   </td>
   <td>4096
   </td>
   <td>No
   </td>
   <td>No
   </td>
   <td>/v1/chat/completions
   </td>
  </tr>
  <tr>
   <td>‚úîÔ∏è
   </td>
   <td>claude-instant-1.0
   </td>
   <td>Claude Instant v1.0
   </td>
   <td>Anthhropic‚Äôs small and fast model, a predecessor of Claude Haiku.
   </td>
   <td>anthropic
   </td>
   <td>2
   </td>
   <td>No
   </td>
   <td>100000
   </td>
   <td>4096
   </td>
   <td>No
   </td>
   <td>No
   </td>
   <td>/v1/chat/completions
   </td>
  </tr>
  <tr>
   <td>üí∞
   </td>
   <td>meta-llama-3-70b-instruct
   </td>
   <td>Llama 3 70b Instruct
   </td>
   <td>Meta‚Äôs latest class of model (Llama 3) launched with a variety of sizes & flavors. This 70B instruct-tuned version was optimized for high quality dialogue usecases.
   </td>
   <td>meta
   </td>
   <td>2
   </td>
   <td>No
   </td>
   <td>8192
   </td>
   <td>4096
   </td>
   <td>No
   </td>
   <td>No
   </td>
   <td>/v1/chat/completions
   </td>
  </tr>
  <tr>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
  </tr>
  <tr>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>It has demonstrated strong performance compared to leading closed-source models in human evaluations.
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
  </tr>
  <tr>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
  </tr>
  <tr>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>To read more about the model release, <a href="https://ai.meta.com/blog/meta-llama-3/">click here</a>. Usage of this model is subject to <a href="https://llama.meta.com/llama3/use-policy/">Meta‚Äôs Acceptable Use Policy</a>.
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
  </tr>
  <tr>
   <td>üí∞
   </td>
   <td>meta-llama-3-70b-instruct
   </td>
   <td>Llama 3 70b Instruct
   </td>
   <td>Meta‚Äôs latest class of model (Llama 3) launched with a variety of sizes & flavors. This 70B instruct-tuned version was optimized for high quality dialogue usecases.
   </td>
   <td>meta
   </td>
   <td>2
   </td>
   <td>No
   </td>
   <td>8192
   </td>
   <td>4096
   </td>
   <td>No
   </td>
   <td>No
   </td>
   <td>/v1/chat/completions
   </td>
  </tr>
  <tr>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
  </tr>
  <tr>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>It has demonstrated strong performance compared to leading closed-source models in human evaluations.
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
  </tr>
  <tr>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
  </tr>
  <tr>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>To read more about the model release, <a href="https://ai.meta.com/blog/meta-llama-3/">click here</a>. Usage of this model is subject to <a href="https://llama.meta.com/llama3/use-policy/">Meta‚Äôs Acceptable Use Policy</a>.
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
  </tr>
  <tr>
   <td>üí∞
   </td>
   <td>meta-llama-3-8b-instruct
   </td>
   <td>Llama 3 8b Instruct
   </td>
   <td>Meta‚Äôs latest class of model (Llama 3) launched with a variety of sizes & flavors. This 8B instruct-tuned version was optimized for high quality dialogue usecases.
   </td>
   <td>meta
   </td>
   <td>1
   </td>
   <td>No
   </td>
   <td>8192
   </td>
   <td>4096
   </td>
   <td>No
   </td>
   <td>No
   </td>
   <td>/v1/chat/completions
   </td>
  </tr>
  <tr>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
  </tr>
  <tr>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>It has demonstrated strong performance compared to leading closed-source models in human evaluations.
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
  </tr>
  <tr>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
  </tr>
  <tr>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>To read more about the model release, <a href="https://ai.meta.com/blog/meta-llama-3/">click here</a>. Usage of this model is subject to <a href="https://llama.meta.com/llama3/use-policy/">Meta‚Äôs Acceptable Use Policy</a>.
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
  </tr>
  <tr>
   <td>üí∞
   </td>
   <td>meta-llama-3-8b-instruct
   </td>
   <td>Llama 3 8b Instruct
   </td>
   <td>Meta‚Äôs latest class of model (Llama 3) launched with a variety of sizes & flavors. This 8B instruct-tuned version was optimized for high quality dialogue usecases.
   </td>
   <td>meta
   </td>
   <td>1
   </td>
   <td>No
   </td>
   <td>8192
   </td>
   <td>4096
   </td>
   <td>No
   </td>
   <td>No
   </td>
   <td>/v1/chat/completions
   </td>
  </tr>
  <tr>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
  </tr>
  <tr>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>It has demonstrated strong performance compared to leading closed-source models in human evaluations.
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
  </tr>
  <tr>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
  </tr>
  <tr>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>To read more about the model release, <a href="https://ai.meta.com/blog/meta-llama-3/">click here</a>. Usage of this model is subject to <a href="https://llama.meta.com/llama3/use-policy/">Meta‚Äôs Acceptable Use Policy</a>.
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
  </tr>
  <tr>
   <td>üí∞
   </td>
   <td>llama-3-sonar-large-32k-online
   </td>
   <td>Llama 3 Sonar Large 32k Online
   </td>
   <td>From perplexity labs, large llama 3 32k with live web search.
   </td>
   <td>perplexitylabs
   </td>
   <td>2
   </td>
   <td>No
   </td>
   <td>32768
   </td>
   <td>4096
   </td>
   <td>No
   </td>
   <td>No
   </td>
   <td>/v1/chat/completions
   </td>
  </tr>
  <tr>
   <td>üí∞
   </td>
   <td>llama-3-sonar-small-32k-online
   </td>
   <td>Llama 3 Sonar Small 32k Online
   </td>
   <td>From perplexity labs, small llama 3 32k with live web search.
   </td>
   <td>perplexitylabs
   </td>
   <td>2
   </td>
   <td>No
   </td>
   <td>32768
   </td>
   <td>4096
   </td>
   <td>No
   </td>
   <td>No
   </td>
   <td>/v1/chat/completions
   </td>
  </tr>
  <tr>
   <td>üí∞
   </td>
   <td>llama-3-sonar-large-32k-chat
   </td>
   <td>Llama 3 Sonar Large 32k Chat
   </td>
   <td>From perplexity labs, large llama 3 32k.
   </td>
   <td>perplexitylabs
   </td>
   <td>2
   </td>
   <td>No
   </td>
   <td>32768
   </td>
   <td>4096
   </td>
   <td>No
   </td>
   <td>No
   </td>
   <td>/v1/chat/completions
   </td>
  </tr>
  <tr>
   <td>üí∞
   </td>
   <td>llama-3-sonar-small-32k-chat
   </td>
   <td>Llama 3 Sonar Small 32k Chat
   </td>
   <td>From perplexity labs, small llama 3 32k.
   </td>
   <td>perplexitylabs
   </td>
   <td>2
   </td>
   <td>No
   </td>
   <td>32768
   </td>
   <td>4096
   </td>
   <td>No
   </td>
   <td>No
   </td>
   <td>/v1/chat/completions
   </td>
  </tr>
  <tr>
   <td>üí∞
   </td>
   <td>blackbox
   </td>
   <td>Blackbox AI
   </td>
   <td>The Blackbox AI model (amazing with coding and tasks in general), in API form.
   </td>
   <td>blackbox
   </td>
   <td>1
   </td>
   <td>No
   </td>
   <td>N/A
   </td>
   <td>N/A
   </td>
   <td>Yes
   </td>
   <td>No
   </td>
   <td>/v1/chat/completions
   </td>
  </tr>
  <tr>
   <td>üí∞
   </td>
   <td>blackbox-code
   </td>
   <td>BlackBox Code
   </td>
   <td>The Blackbox AI model (amazing with coding), in API form.
   </td>
   <td>blackbox
   </td>
   <td>1
   </td>
   <td>No
   </td>
   <td>N/A
   </td>
   <td>N/A
   </td>
   <td>Yes
   </td>
   <td>No
   </td>
   <td>/v1/chat/completions
   </td>
  </tr>
  <tr>
   <td>‚úîÔ∏è
   </td>
   <td>wizardlm-2-8x22b
   </td>
   <td>WizardLM 2 8x22B
   </td>
   <td>WizardLM-2 8x22B is Microsoft AI‚Äôs most advanced Wizard model. It demonstrates highly competitive performance compared to those leading proprietary models.
   </td>
   <td>microsoft
   </td>
   <td>3
   </td>
   <td>Yes
   </td>
   <td>65536
   </td>
   <td>4096
   </td>
   <td>No
   </td>
   <td>No
   </td>
   <td>/v1/chat/completions
   </td>
  </tr>
  <tr>
   <td>‚úîÔ∏è
   </td>
   <td>wizardlm-2-70b
   </td>
   <td>WizardLM 2 70b
   </td>
   <td>WizardLM-2 7B is the smaller variant of Microsoft AI‚Äôs latest Wizard model. It is the fastest and achieves comparable performance with existing 10x larger open-source leading models
   </td>
   <td>microsoft
   </td>
   <td>2
   </td>
   <td>No
   </td>
   <td>32768
   </td>
   <td>4096
   </td>
   <td>No
   </td>
   <td>No
   </td>
   <td>/v1/chat/completions
   </td>
  </tr>
  <tr>
   <td>‚úîÔ∏è
   </td>
   <td>dolphin-2.6-mixtral-8x7b
   </td>
   <td>Dolphin 2.6 Mixtral 8x7B
   </td>
   <td>The Dolphin 2.6 Mixtral 8x7b model is a finetuned version of the Mixtral-8x7b model, trained on a variety of data including coding data, for 3 days on 4 A100 GPUs. It is uncensored and requires trust_remote_code. The model is very obedient and good at coding, but not DPO tuned. The dataset has been filtered for alignment and bias. The model is compliant with user requests and can be used for various purposes such as generating code or engaging in general chat.
   </td>
   <td>cognitivecomputations
   </td>
   <td>1
   </td>
   <td>No
   </td>
   <td>32768
   </td>
   <td>32768
   </td>
   <td>No
   </td>
   <td>No
   </td>
   <td>/v1/chat/completions
   </td>
  </tr>
  <tr>
   <td>‚úîÔ∏è
   </td>
   <td>dolphin-2.6-mixtral-8x7b
   </td>
   <td>Dolphin 2.6 Mixtral 8x7B
   </td>
   <td>The Dolphin 2.6 Mixtral 8x7b model is a finetuned version of the Mixtral-8x7b model, trained on a variety of data including coding data, for 3 days on 4 A100 GPUs. It is uncensored and requires trust_remote_code. The model is very obedient and good at coding, but not DPO tuned. The dataset has been filtered for alignment and bias. The model is compliant with user requests and can be used for various purposes such as generating code or engaging in general chat.
   </td>
   <td>cognitivecomputations
   </td>
   <td>1
   </td>
   <td>No
   </td>
   <td>32768
   </td>
   <td>32768
   </td>
   <td>No
   </td>
   <td>No
   </td>
   <td>/v1/chat/completions
   </td>
  </tr>
  <tr>
   <td>üí∞
   </td>
   <td>codestral-latest
   </td>
   <td>Codestral Latest
   </td>
   <td>Mistral‚Äôs latest code model.
   </td>
   <td>mistral
   </td>
   <td>1
   </td>
   <td>No
   </td>
   <td>32768
   </td>
   <td>4096
   </td>
   <td>No
   </td>
   <td>No
   </td>
   <td>/v1/chat/completions
   </td>
  </tr>
  <tr>
   <td>üí∞
   </td>
   <td>codestral-latest
   </td>
   <td>Codestral Latest
   </td>
   <td>Mistral‚Äôs latest code model.
   </td>
   <td>mistral
   </td>
   <td>1
   </td>
   <td>No
   </td>
   <td>32768
   </td>
   <td>4096
   </td>
   <td>No
   </td>
   <td>No
   </td>
   <td>/v1/chat/completions
   </td>
  </tr>
  <tr>
   <td>üí∞
   </td>
   <td>codestral-latest
   </td>
   <td>Codestral Latest
   </td>
   <td>Mistral‚Äôs latest code model.
   </td>
   <td>mistral
   </td>
   <td>1
   </td>
   <td>No
   </td>
   <td>32768
   </td>
   <td>4096
   </td>
   <td>No
   </td>
   <td>No
   </td>
   <td>/v1/chat/completions
   </td>
  </tr>
  <tr>
   <td>üí∞
   </td>
   <td>codestral-latest
   </td>
   <td>Codestral Latest
   </td>
   <td>Mistral‚Äôs latest code model.
   </td>
   <td>mistral
   </td>
   <td>1
   </td>
   <td>No
   </td>
   <td>32768
   </td>
   <td>4096
   </td>
   <td>No
   </td>
   <td>No
   </td>
   <td>/v1/chat/completions
   </td>
  </tr>
  <tr>
   <td>üí∞
   </td>
   <td>mistral-large
   </td>
   <td>Mistral Large
   </td>
   <td>Mistral‚Äôs Latest and Largest Model.
   </td>
   <td>mistralai
   </td>
   <td>5
   </td>
   <td>No
   </td>
   <td>32768
   </td>
   <td>8192
   </td>
   <td>No
   </td>
   <td>No
   </td>
   <td>/v1/chat/completions
   </td>
  </tr>
  <tr>
   <td>üí∞
   </td>
   <td>mistral-next
   </td>
   <td>Mistral Next
   </td>
   <td>Mistral‚Äôs prototype extra concision Model.
   </td>
   <td>mistralai
   </td>
   <td>4
   </td>
   <td>No
   </td>
   <td>32768
   </td>
   <td>4096
   </td>
   <td>No
   </td>
   <td>No
   </td>
   <td>/v1/chat/completions
   </td>
  </tr>
  <tr>
   <td>‚úîÔ∏è
   </td>
   <td>mistral-medium
   </td>
   <td>Mistral Medium
   </td>
   <td>Mistral‚Äôs Medium Model.
   </td>
   <td>mistralai
   </td>
   <td>4
   </td>
   <td>No
   </td>
   <td>32768
   </td>
   <td>4096
   </td>
   <td>No
   </td>
   <td>No
   </td>
   <td>/v1/chat/completions
   </td>
  </tr>
  <tr>
   <td>üí∞
   </td>
   <td>mistral-small
   </td>
   <td>Mistral Small
   </td>
   <td>Mistral‚Äôs Small Model.
   </td>
   <td>mistralai
   </td>
   <td>4
   </td>
   <td>No
   </td>
   <td>32768
   </td>
   <td>4096
   </td>
   <td>No
   </td>
   <td>No
   </td>
   <td>/v1/chat/completions
   </td>
  </tr>
  <tr>
   <td>üí∞
   </td>
   <td>mistral-tiny
   </td>
   <td>Mistral Tiny
   </td>
   <td>Mistral‚Äôs Tiny Model.
   </td>
   <td>mistralai
   </td>
   <td>3
   </td>
   <td>No
   </td>
   <td>32768
   </td>
   <td>4096
   </td>
   <td>No
   </td>
   <td>No
   </td>
   <td>/v1/chat/completions
   </td>
  </tr>
  <tr>
   <td>‚úîÔ∏è
   </td>
   <td>mixtral-8x7b-instruct-v0.1
   </td>
   <td>Mixtral 8x7b Instruct
   </td>
   <td>The Mixtral-8x7B Large Language Model (LLM) is a pretrained generative Sparse Mixture of Experts. The Mixtral-8x7B outperforms Llama 2 70B on most benchmarks tested.
   </td>
   <td>mistralai
   </td>
   <td>1
   </td>
   <td>No
   </td>
   <td>32768
   </td>
   <td>32768
   </td>
   <td>No
   </td>
   <td>No
   </td>
   <td>/v1/chat/completions
   </td>
  </tr>
  <tr>
   <td>‚úîÔ∏è
   </td>
   <td>mixtral-8x7b-instruct-v0.1
   </td>
   <td>Mixtral 8x7b Instruct
   </td>
   <td>The Mixtral-8x7B Large Language Model (LLM) is a pretrained generative Sparse Mixture of Experts. The Mixtral-8x7B outperforms Llama 2 70B on most benchmarks tested.
   </td>
   <td>mistralai
   </td>
   <td>1
   </td>
   <td>No
   </td>
   <td>32768
   </td>
   <td>32768
   </td>
   <td>No
   </td>
   <td>No
   </td>
   <td>/v1/chat/completions
   </td>
  </tr>
  <tr>
   <td>‚úîÔ∏è
   </td>
   <td>mixtral-8x22b-instruct-v0.1
   </td>
   <td>Mixtral 8x22b Instruct
   </td>
   <td>The Mixtral-8x22B Large Language Model (LLM) is a pretrained generative Sparse Mixture of Experts. The Mixtral-8x22B outperforms Llama 2 70B on most benchmarks tested.
   </td>
   <td>mistralai
   </td>
   <td>3
   </td>
   <td>No
   </td>
   <td>32768
   </td>
   <td>32768
   </td>
   <td>No
   </td>
   <td>No
   </td>
   <td>/v1/chat/completions
   </td>
  </tr>
  <tr>
   <td>‚úîÔ∏è
   </td>
   <td>mixtral-8x22b-instruct-v0.1
   </td>
   <td>Mixtral 8x22b Instruct
   </td>
   <td>The Mixtral-8x22B Large Language Model (LLM) is a pretrained generative Sparse Mixture of Experts. The Mixtral-8x22B outperforms Llama 2 70B on most benchmarks tested.
   </td>
   <td>mistralai
   </td>
   <td>3
   </td>
   <td>No
   </td>
   <td>32768
   </td>
   <td>32768
   </td>
   <td>No
   </td>
   <td>No
   </td>
   <td>/v1/chat/completions
   </td>
  </tr>
  <tr>
   <td>‚úîÔ∏è
   </td>
   <td>mistral-7b-instruct-v0.2
   </td>
   <td>Mistral 7B Instruct 2
   </td>
   <td>A 7.3B parameter model that outperforms Llama 2 13B on all benchmarks, with optimizations for speed and context length.
   </td>
   <td>mistralai
   </td>
   <td>1
   </td>
   <td>Yes
   </td>
   <td>32768
   </td>
   <td>8192
   </td>
   <td>No
   </td>
   <td>No
   </td>
   <td>/v1/chat/completions
   </td>
  </tr>
  <tr>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
  </tr>
  <tr>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>This is v0.2 of Mistral 7B Instruct.
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
  </tr>
  <tr>
   <td>‚úîÔ∏è
   </td>
   <td>mistral-7b-instruct-v0.2
   </td>
   <td>Mistral 7B Instruct 2
   </td>
   <td>A 7.3B parameter model that outperforms Llama 2 13B on all benchmarks, with optimizations for speed and context length.
   </td>
   <td>mistralai
   </td>
   <td>1
   </td>
   <td>Yes
   </td>
   <td>32768
   </td>
   <td>8192
   </td>
   <td>No
   </td>
   <td>No
   </td>
   <td>/v1/chat/completions
   </td>
  </tr>
  <tr>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
  </tr>
  <tr>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>This is v0.2 of Mistral 7B Instruct.
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
  </tr>
  <tr>
   <td>‚úîÔ∏è
   </td>
   <td>mistral-7b-instruct-v0.1
   </td>
   <td>Mistral 7B Instruct
   </td>
   <td>A 7.3B parameter model that outperforms Llama 2 13B on all benchmarks, with optimizations for speed and context length.
   </td>
   <td>mistralai
   </td>
   <td>1
   </td>
   <td>No
   </td>
   <td>32768
   </td>
   <td>32768
   </td>
   <td>No
   </td>
   <td>No
   </td>
   <td>/v1/chat/completions
   </td>
  </tr>
  <tr>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
  </tr>
  <tr>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>This is v0.1 of Mistral 7B Instruct.
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
  </tr>
  <tr>
   <td>‚úîÔ∏è
   </td>
   <td>mistral-7b-instruct-v0.1
   </td>
   <td>Mistral 7B Instruct
   </td>
   <td>A 7.3B parameter model that outperforms Llama 2 13B on all benchmarks, with optimizations for speed and context length.
   </td>
   <td>mistralai
   </td>
   <td>1
   </td>
   <td>No
   </td>
   <td>32768
   </td>
   <td>32768
   </td>
   <td>No
   </td>
   <td>No
   </td>
   <td>/v1/chat/completions
   </td>
  </tr>
  <tr>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
  </tr>
  <tr>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>This is v0.1 of Mistral 7B Instruct.
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
  </tr>
  <tr>
   <td>‚úîÔ∏è
   </td>
   <td>nous-hermes-2-mixtral-8x7b
   </td>
   <td>Nous Hermes 2 Mixtral 8x7B
   </td>
   <td>The Nous Hermes 2 Mixtral 8x7B model is a finetuned version of the Mixtral-8x7b model, trained on a variety of data including coding data, for 3 days on 4 A100 GPUs. It is uncensored and requires trust_remote_code. The model is very obedient and good at coding, but not DPO tuned. The dataset has been filtered for alignment and bias. The model is compliant with user requests and can be used for various purposes such as generating code or engaging in general chat.
   </td>
   <td>nous-hermes
   </td>
   <td>3
   </td>
   <td>No
   </td>
   <td>32768
   </td>
   <td>32768
   </td>
   <td>No
   </td>
   <td>No
   </td>
   <td>/v1/chat/completions
   </td>
  </tr>
  <tr>
   <td>üí∞
   </td>
   <td>gemini-1.5-pro-latest
   </td>
   <td>Gemini 1.5 Pro
   </td>
   <td>Mid-size multimodal model that supports up to 1 million tokens.
   </td>
   <td>google
   </td>
   <td>5
   </td>
   <td>Yes
   </td>
   <td>1048576
   </td>
   <td>8192
   </td>
   <td>Yes
   </td>
   <td>Yes
   </td>
   <td>/v1/chat/completions
   </td>
  </tr>
  <tr>
   <td>üí∞
   </td>
   <td>gemini-1.5-pro-latest
   </td>
   <td>Gemini 1.5 Pro
   </td>
   <td>Mid-size multimodal model that supports up to 1 million tokens.
   </td>
   <td>google
   </td>
   <td>5
   </td>
   <td>Yes
   </td>
   <td>1048576
   </td>
   <td>8192
   </td>
   <td>Yes
   </td>
   <td>Yes
   </td>
   <td>/v1/chat/completions
   </td>
  </tr>
  <tr>
   <td>üí∞
   </td>
   <td>gemini-1.0-pro-latest
   </td>
   <td>Gemini 1.0 Pro Latest
   </td>
   <td>The best model for scaling across a wide range of tasks. This is the latest model.
   </td>
   <td>google
   </td>
   <td>1
   </td>
   <td>Yes
   </td>
   <td>30720
   </td>
   <td>2048
   </td>
   <td>Yes
   </td>
   <td>No
   </td>
   <td>/v1/chat/completions
   </td>
  </tr>
  <tr>
   <td>üí∞
   </td>
   <td>gemini-1.0-pro-latest
   </td>
   <td>Gemini 1.0 Pro Latest
   </td>
   <td>The best model for scaling across a wide range of tasks. This is the latest model.
   </td>
   <td>google
   </td>
   <td>1
   </td>
   <td>Yes
   </td>
   <td>30720
   </td>
   <td>2048
   </td>
   <td>Yes
   </td>
   <td>No
   </td>
   <td>/v1/chat/completions
   </td>
  </tr>
  <tr>
   <td>üí∞
   </td>
   <td>gemini-1.0-pro-latest
   </td>
   <td>Gemini 1.0 Pro Latest
   </td>
   <td>The best model for scaling across a wide range of tasks. This is the latest model.
   </td>
   <td>google
   </td>
   <td>1
   </td>
   <td>Yes
   </td>
   <td>30720
   </td>
   <td>2048
   </td>
   <td>Yes
   </td>
   <td>No
   </td>
   <td>/v1/chat/completions
   </td>
  </tr>
  <tr>
   <td>üí∞
   </td>
   <td>gemini-1.0-pro-vision
   </td>
   <td>Gemini 1.0 Pro Vision
   </td>
   <td>The best image understanding model to handle a broad range of applications.
   </td>
   <td>google
   </td>
   <td>1
   </td>
   <td>No
   </td>
   <td>12288
   </td>
   <td>4096
   </td>
   <td>Yes
   </td>
   <td>No
   </td>
   <td>/v1/chat/completions
   </td>
  </tr>
  <tr>
   <td>üí∞
   </td>
   <td>gemini-1.0-pro-vision
   </td>
   <td>Gemini 1.0 Pro Vision
   </td>
   <td>The best image understanding model to handle a broad range of applications.
   </td>
   <td>google
   </td>
   <td>1
   </td>
   <td>No
   </td>
   <td>12288
   </td>
   <td>4096
   </td>
   <td>Yes
   </td>
   <td>No
   </td>
   <td>/v1/chat/completions
   </td>
  </tr>
  <tr>
   <td>üí∞
   </td>
   <td>lzlv-70b
   </td>
   <td>lzlv 70B
   </td>
   <td>A Mythomax/MLewd_13B-style merge of selected 70B models A multi-model merge of several LLaMA2 70B finetunes for roleplaying and creative work. The goal was to create a model that combines creativity with intelligence for an enhanced experience.
   </td>
   <td>unknown
   </td>
   <td>1
   </td>
   <td>No
   </td>
   <td>4096
   </td>
   <td>4096
   </td>
   <td>No
   </td>
   <td>No
   </td>
   <td>/v1/chat/completions
   </td>
  </tr>
  <tr>
   <td>üí∞
   </td>
   <td>figgs-rp
   </td>
   <td>Figgs RP
   </td>
   <td>Figgs RP is from figgs.ai. Great AI, great RP.
   </td>
   <td>figgsai
   </td>
   <td>1
   </td>
   <td>No
   </td>
   <td>4096
   </td>
   <td>4096
   </td>
   <td>No
   </td>
   <td>No
   </td>
   <td>/v1/chat/completions
   </td>
  </tr>
  <tr>
   <td>üí∞
   </td>
   <td>cinematika-7b
   </td>
   <td>Cinematika 7B
   </td>
   <td>Cinematika 7B is a large language model trained on a variety of data including coding data, for 3 days on 4 A100 GPUs. It is uncensored and requires trust_remote_code. The model is very obedient and good at coding, but not DPO tuned. The dataset has been filtered for alignment and bias. The model is compliant with user requests and can be used for various purposes such as generating code or engaging in general chat.
   </td>
   <td>cinematika
   </td>
   <td>1
   </td>
   <td>No
   </td>
   <td>8000
   </td>
   <td>8000
   </td>
   <td>No
   </td>
   <td>No
   </td>
   <td>/v1/chat/completions
   </td>
  </tr>
  <tr>
   <td>‚úîÔ∏è
   </td>
   <td>shuttle-diffusion
   </td>
   <td>Shuttle Diffusion
   </td>
   <td>Shuttle-Diffusion is our newest Shuttle hosted image model, surpassing SDXL, Playground v2, PixArt-a, DALL-E 3, and Midjourney 5.2. It generates images in ~4 seconds, hosted on our A100 (80GB) server, and is available for free.
   </td>
   <td>shuttleai
   </td>
   <td>1
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>/v1/images/generations
   </td>
  </tr>
  <tr>
   <td>üí∞
   </td>
   <td>dall-e-3
   </td>
   <td>DALL-E 3
   </td>
   <td>DALL-E 3 is a model that generates images from text.
   </td>
   <td>openai
   </td>
   <td>5
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>/v1/images/generations
   </td>
  </tr>
  <tr>
   <td>‚úîÔ∏è
   </td>
   <td>sdxl
   </td>
   <td>SDXL
   </td>
   <td>The original SD-XL model from stabilityai.
   </td>
   <td>stabilityai
   </td>
   <td>1
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>/v1/images/generations
   </td>
  </tr>
  <tr>
   <td>‚úîÔ∏è
   </td>
   <td>sdxl-emoji
   </td>
   <td>SDXL Emoji
   </td>
   <td>SDXL finetuned on Apple emojis.
   </td>
   <td>stabilityai/fofr
   </td>
   <td>1
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>/v1/images/generations
   </td>
  </tr>
  <tr>
   <td>‚úîÔ∏è
   </td>
   <td>dreamshaper-xl
   </td>
   <td>Dreamshaper XL
   </td>
   <td>Dreamshaper XL is an excellent uncensored text to imagine model.
   </td>
   <td>stabilityai
   </td>
   <td>3
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>/v1/images/generations
   </td>
  </tr>
  <tr>
   <td>‚úîÔ∏è
   </td>
   <td>juggernaut-xl
   </td>
   <td>Juggernaut XL
   </td>
   <td>Juggernaut SDXL model.
   </td>
   <td>stabilityai
   </td>
   <td>2
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>/v1/images/generations
   </td>
  </tr>
  <tr>
   <td>‚úîÔ∏è
   </td>
   <td>dynavision-xl
   </td>
   <td>Dynavision XL
   </td>
   <td>Dynavision XL model from stabilityai.
   </td>
   <td>stabilityai
   </td>
   <td>2
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>/v1/images/generations
   </td>
  </tr>
  <tr>
   <td>‚úîÔ∏è
   </td>
   <td>realism-engine-xl
   </td>
   <td>Realism Engine XL
   </td>
   <td>Realism Engine XL model for high fidelity image generation.
   </td>
   <td>stabilityai
   </td>
   <td>2
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>/v1/images/generations
   </td>
  </tr>
  <tr>
   <td>‚úîÔ∏è
   </td>
   <td>sdxl-inpainting
   </td>
   <td>SDXL Inpainting
   </td>
   <td>Inpainting model based on the SDXL framework.
   </td>
   <td>stabilityai
   </td>
   <td>4
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>/v1/images/generations
   </td>
  </tr>
  <tr>
   <td>‚úîÔ∏è
   </td>
   <td>turbovision-xl
   </td>
   <td>Turbovision XL
   </td>
   <td>Turbovision XL, an advanced image generation model.
   </td>
   <td>stabilityai
   </td>
   <td>2
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>/v1/images/generations
   </td>
  </tr>
  <tr>
   <td>‚úîÔ∏è
   </td>
   <td>kandinsky-2.2
   </td>
   <td>Kandinsky 2.2
   </td>
   <td>Kandinsky 2.2 by Sberbank.
   </td>
   <td>sberbank
   </td>
   <td>1
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>/v1/images/generations
   </td>
  </tr>
  <tr>
   <td>‚úîÔ∏è
   </td>
   <td>kandinsky-2
   </td>
   <td>Kandinsky 2
   </td>
   <td>Kandinsky 2 by Sberbank.
   </td>
   <td>sberbank
   </td>
   <td>1
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>/v1/images/generations
   </td>
  </tr>
  <tr>
   <td>‚úîÔ∏è
   </td>
   <td>stable-diffusion-2.1
   </td>
   <td>Stable Diffusion 2.1
   </td>
   <td>Stable Diffusion version 2.1 from stabilityai.
   </td>
   <td>stabilityai
   </td>
   <td>1
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>/v1/images/generations
   </td>
  </tr>
  <tr>
   <td>‚úîÔ∏è
   </td>
   <td>stable-diffusion-1.5
   </td>
   <td>Stable Diffusion 1.5
   </td>
   <td>Stable Diffusion version 1.5 from stabilityai.
   </td>
   <td>stabilityai
   </td>
   <td>1
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>/v1/images/generations
   </td>
  </tr>
  <tr>
   <td>‚úîÔ∏è
   </td>
   <td>playground-v2.5
   </td>
   <td>Playground v2.5
   </td>
   <td>A ShuttleAI model.
   </td>
   <td>playgroundai
   </td>
   <td>4
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>/v1/images/generations
   </td>
  </tr>
  <tr>
   <td>‚úîÔ∏è
   </td>
   <td>dreamshaper-v8
   </td>
   <td>Dreamshaper v8
   </td>
   <td>Dreamshaper v8 is an excellent uncensored text to imagine model.
   </td>
   <td>stabilityai
   </td>
   <td>1
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>/v1/images/generations
   </td>
  </tr>
  <tr>
   <td>‚úîÔ∏è
   </td>
   <td>rev-animated
   </td>
   <td>Rev Animated
   </td>
   <td>Rev Animated model for dynamic animations.
   </td>
   <td>stabilityai
   </td>
   <td>1
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>/v1/images/generations
   </td>
  </tr>
  <tr>
   <td>‚úîÔ∏è
   </td>
   <td>anything-v5
   </td>
   <td>Anything V5
   </td>
   <td>Versatile generation model for various images.
   </td>
   <td>stabilityai
   </td>
   <td>1
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>/v1/images/generations
   </td>
  </tr>
  <tr>
   <td>‚úîÔ∏è
   </td>
   <td>absolutereality-v1.8.1
   </td>
   <td>Absolute Reality V1.8.1
   </td>
   <td>High fidelity reality simulation model.
   </td>
   <td>stabilityai
   </td>
   <td>1
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>/v1/images/generations
   </td>
  </tr>
  <tr>
   <td>‚úîÔ∏è
   </td>
   <td>realisticvision-v5
   </td>
   <td>Realistic Vision V5
   </td>
   <td>Advanced realism in visual generation.
   </td>
   <td>stabilityai
   </td>
   <td>1
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>/v1/images/generations
   </td>
  </tr>
  <tr>
   <td>‚úîÔ∏è
   </td>
   <td>timeless-v1
   </td>
   <td>Timeless V1
   </td>
   <td>Creates timeless artistic images.
   </td>
   <td>stabilityai
   </td>
   <td>1
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>/v1/images/generations
   </td>
  </tr>
  <tr>
   <td>‚úîÔ∏è
   </td>
   <td>portrait-v1
   </td>
   <td>Portrait V1
   </td>
   <td>Specialized in generating detailed portraits.
   </td>
   <td>stabilityai
   </td>
   <td>1
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>/v1/images/generations
   </td>
  </tr>
  <tr>
   <td>‚úîÔ∏è
   </td>
   <td>analog
   </td>
   <td>Analog
   </td>
   <td>Emulates analog photographic techniques.
   </td>
   <td>stabilityai
   </td>
   <td>1
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>/v1/images/generations
   </td>
  </tr>
  <tr>
   <td>‚úîÔ∏è
   </td>
   <td>anything-v3
   </td>
   <td>Anything V3
   </td>
   <td>Flexible image generation for a variety of themes.
   </td>
   <td>stabilityai
   </td>
   <td>1
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>/v1/images/generations
   </td>
  </tr>
  <tr>
   <td>‚úîÔ∏è
   </td>
   <td>anything-v4
   </td>
   <td>Anything V4
   </td>
   <td>Enhanced version for broader image generation capabilities.
   </td>
   <td>stabilityai
   </td>
   <td>1
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>/v1/images/generations
   </td>
  </tr>
  <tr>
   <td>‚úîÔ∏è
   </td>
   <td>abyssorangemix
   </td>
   <td>Abyss Orange Mix
   </td>
   <td>Unique blend of deep learning models for vibrant artistic output.
   </td>
   <td>stabilityai
   </td>
   <td>1
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>/v1/images/generations
   </td>
  </tr>
  <tr>
   <td>‚úîÔ∏è
   </td>
   <td>deliberate
   </td>
   <td>Deliberate
   </td>
   <td>Crafts images with a deliberate artistic touch.
   </td>
   <td>stabilityai
   </td>
   <td>1
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>/v1/images/generations
   </td>
  </tr>
  <tr>
   <td>‚úîÔ∏è
   </td>
   <td>dreamlike-v1
   </td>
   <td>Dreamlike V1
   </td>
   <td>Generates ethereal and dream-like images.
   </td>
   <td>stabilityai
   </td>
   <td>1
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>/v1/images/generations
   </td>
  </tr>
  <tr>
   <td>‚úîÔ∏è
   </td>
   <td>dreamlike-v2
   </td>
   <td>Dreamlike V2
   </td>
   <td>Second version with enhanced capabilities for dreamy visuals.
   </td>
   <td>stabilityai
   </td>
   <td>1
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>/v1/images/generations
   </td>
  </tr>
  <tr>
   <td>‚úîÔ∏è
   </td>
   <td>dreamshaper-5
   </td>
   <td>Dreamshaper 5
   </td>
   <td>Fifth iteration of the model designed for creative image synthesis.
   </td>
   <td>stabilityai
   </td>
   <td>1
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>/v1/images/generations
   </td>
  </tr>
  <tr>
   <td>‚úîÔ∏è
   </td>
   <td>dreamshaper-6
   </td>
   <td>Dreamshaper 6
   </td>
   <td>Improved Dreamshaper model for even more imaginative outputs.
   </td>
   <td>stabilityai
   </td>
   <td>1
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>/v1/images/generations
   </td>
  </tr>
  <tr>
   <td>‚úîÔ∏è
   </td>
   <td>elldrethvividmix
   </td>
   <td>Elldreth Vivid Mix
   </td>
   <td>Combines multiple artistic styles into vivid creations.
   </td>
   <td>stabilityai
   </td>
   <td>1
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>/v1/images/generations
   </td>
  </tr>
  <tr>
   <td>‚úîÔ∏è
   </td>
   <td>lyriel-v15
   </td>
   <td>Lyriel V15
   </td>
   <td>15th version of the Lyriel model, specialized in high-detail image generation.
   </td>
   <td>stabilityai
   </td>
   <td>1
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>/v1/images/generations
   </td>
  </tr>
  <tr>
   <td>‚úîÔ∏è
   </td>
   <td>lyriel-v16
   </td>
   <td>Lyriel V16
   </td>
   <td>Latest iteration of the Lyriel series with improved generative abilities.
   </td>
   <td>stabilityai
   </td>
   <td>1
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>/v1/images/generations
   </td>
  </tr>
  <tr>
   <td>‚úîÔ∏è
   </td>
   <td>mechamix
   </td>
   <td>Mechamix
   </td>
   <td>Focuses on generating mechanical and robotic imagery.
   </td>
   <td>stabilityai
   </td>
   <td>1
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>/v1/images/generations
   </td>
  </tr>
  <tr>
   <td>‚úîÔ∏è
   </td>
   <td>meinamix
   </td>
   <td>Meina Mix
   </td>
   <td>Meina Mix for a unique blend of modern and traditional art styles.
   </td>
   <td>stabilityai
   </td>
   <td>1
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>/v1/images/generations
   </td>
  </tr>
  <tr>
   <td>‚úîÔ∏è
   </td>
   <td>realisticvs-v14
   </td>
   <td>RealisticVS V14
   </td>
   <td>14th version of RealisticVS, focused on ultra-realistic visual synthesis.
   </td>
   <td>stabilityai
   </td>
   <td>1
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>/v1/images/generations
   </td>
  </tr>
  <tr>
   <td>‚úîÔ∏è
   </td>
   <td>realisticvs-v20
   </td>
   <td>RealisticVS V20
   </td>
   <td>20th version offering advanced realism and detail in image generation.
   </td>
   <td>stabilityai
   </td>
   <td>1
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>/v1/images/generations
   </td>
  </tr>
  <tr>
   <td>‚úîÔ∏è
   </td>
   <td>riffusion
   </td>
   <td>Riffusion
   </td>
   <td>Specializes in generating images inspired by music and sound.
   </td>
   <td>stabilityai
   </td>
   <td>1
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>/v1/images/generations
   </td>
  </tr>
  <tr>
   <td>‚úîÔ∏è
   </td>
   <td>sd-v14
   </td>
   <td>SD V14
   </td>
   <td>14th version of the Stable Diffusion model with enhanced capabilities.
   </td>
   <td>stabilityai
   </td>
   <td>1
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>/v1/images/generations
   </td>
  </tr>
  <tr>
   <td>‚úîÔ∏è
   </td>
   <td>sd-v15
   </td>
   <td>SD V15
   </td>
   <td>Latest version of Stable Diffusion, featuring improved performance and quality.
   </td>
   <td>stabilityai
   </td>
   <td>1
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>/v1/images/generations
   </td>
  </tr>
  <tr>
   <td>‚úîÔ∏è
   </td>
   <td>sbp
   </td>
   <td>SBP
   </td>
   <td>SBP model tailored for specific business processes and imagery needs.
   </td>
   <td>stabilityai
   </td>
   <td>1
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>/v1/images/generations
   </td>
  </tr>
  <tr>
   <td>‚úîÔ∏è
   </td>
   <td>theallysmix
   </td>
   <td>The Allys Mix
   </td>
   <td>Creative model that blends multiple artistic influences for unique outputs.
   </td>
   <td>stabilityai
   </td>
   <td>1
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>/v1/images/generations
   </td>
  </tr>
  <tr>
   <td>‚úîÔ∏è
   </td>
   <td>openjourney
   </td>
   <td>Open Journey
   </td>
   <td>Designed for open-ended exploration of artistic and visual possibilities.
   </td>
   <td>stabilityai
   </td>
   <td>1
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>/v1/images/generations
   </td>
  </tr>
  <tr>
   <td>‚úîÔ∏è
   </td>
   <td>icbinp
   </td>
   <td>ICBINP
   </td>
   <td>ICBINP aka I Can‚Äôt Believe It‚Äôs Not Photography, excels in photorealistic images.
   </td>
   <td>seco
   </td>
   <td>1
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>/v1/images/generations
   </td>
  </tr>
  <tr>
   <td>‚úîÔ∏è
   </td>
   <td>latent-consistency-model
   </td>
   <td>Latent Consistency Model
   </td>
   <td>LCMs: The next generation of generative models after Latent Diffusion Models (LDMs), focusing on improved consistency and detail in generative outputs.
   </td>
   <td>LCM
   </td>
   <td>1
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>/v1/images/generations
   </td>
  </tr>
  <tr>
   <td>‚úîÔ∏è
   </td>
   <td>deepfloyd-if
   </td>
   <td>DeepFloyd IF
   </td>
   <td>DeepFloyd‚Äôs IF model, designed for intuitive and fluent image generation, emphasizing creativity and flexibility.
   </td>
   <td>deepfloyd
   </td>
   <td>1
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>/v1/images/generations
   </td>
  </tr>
  <tr>
   <td>‚úîÔ∏è
   </td>
   <td>material-diffusion
   </td>
   <td>Material Diffusion
   </td>
   <td>Material Diffusion, tailored for generating complex material textures and realistic environmental details.
   </td>
   <td>material
   </td>
   <td>1
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>/v1/images/generations
   </td>
  </tr>
  <tr>
   <td>‚úîÔ∏è
   </td>
   <td>eleven-labs
   </td>
   <td>Eleven Labs (Chars: ~333)
   </td>
   <td>Amazing natural sounding AI speech with a variety of voices to choose from, capped at 333 characters per request.
   </td>
   <td>elevenlabs
   </td>
   <td>1
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>/v1/audio/speech
   </td>
  </tr>
  <tr>
   <td>üí∞
   </td>
   <td>eleven-labs-2
   </td>
   <td>Eleven Labs v2 (Chars: ~100)
   </td>
   <td>Newer version of Eleven Labs with improved multi lingual support, but capped at 100 characters per request.
   </td>
   <td>elevenlabs
   </td>
   <td>2
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>/v1/audio/speech
   </td>
  </tr>
  <tr>
   <td>üí∞
   </td>
   <td>eleven-labs-999
   </td>
   <td>Eleven Labs v2 (Chars: ~999)
   </td>
   <td>Newer version of Eleven Labs with improved multi lingual support, but capped at 999 characters per request.
   </td>
   <td>elevenlabs
   </td>
   <td>3
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>/v1/audio/speech
   </td>
  </tr>
  <tr>
   <td>‚úîÔ∏è
   </td>
   <td>speechify
   </td>
   <td>Speechify
   </td>
   <td>Fun Text-to-Speech model with a ton of voices to choose from, including cartoon, celebrity, and casual voices.
   </td>
   <td>speechify
   </td>
   <td>3
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>/v1/audio/speech
   </td>
  </tr>
  <tr>
   <td>üí∞
   </td>
   <td>tts-1
   </td>
   <td>TTS 1
   </td>
   <td>A ShuttleAI model.
   </td>
   <td>openai
   </td>
   <td>4
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>/v1/audio/speech
   </td>
  </tr>
  <tr>
   <td>üí∞
   </td>
   <td>tts-1
   </td>
   <td>TTS 1
   </td>
   <td>A ShuttleAI model.
   </td>
   <td>openai
   </td>
   <td>4
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>/v1/audio/speech
   </td>
  </tr>
  <tr>
   <td>üí∞
   </td>
   <td>tts-1-hd
   </td>
   <td>TTS 1
   </td>
   <td>A ShuttleAI model.
   </td>
   <td>openai
   </td>
   <td>4
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>/v1/audio/speech
   </td>
  </tr>
  <tr>
   <td>üí∞
   </td>
   <td>tts-1-hd
   </td>
   <td>TTS 1
   </td>
   <td>A ShuttleAI model.
   </td>
   <td>openai
   </td>
   <td>4
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>/v1/audio/speech
   </td>
  </tr>
  <tr>
   <td>üí∞
   </td>
   <td>whisper-1
   </td>
   <td>Whisper 1
   </td>
   <td>OpenAI‚Äôs only Official API transcription/translation model; Based off Whisper Large v2.
   </td>
   <td>openai
   </td>
   <td>3
   </td>
   <td>No
   </td>
   <td>N/A
   </td>
   <td>N/A
   </td>
   <td>No
   </td>
   <td>Yes
   </td>
   <td>[‚Äò/v1/audio/transcriptions‚Äô, ‚Äò/v1/audio/translations‚Äô]
   </td>
  </tr>
  <tr>
   <td>‚úîÔ∏è
   </td>
   <td>whisper-large
   </td>
   <td>Whisper Large
   </td>
   <td>Whisper is a pre-trained model for automatic speech recognition (ASR) and speech translation. Trained on 680k hours of labelled data, Whisper models demonstrate a strong ability to generalise to many datasets and domains without the need for fine-tuning.
   </td>
   <td>openai
   </td>
   <td>2
   </td>
   <td>No
   </td>
   <td>N/A
   </td>
   <td>N/A
   </td>
   <td>No
   </td>
   <td>Yes
   </td>
   <td>[‚Äò/v1/audio/transcriptions‚Äô, ‚Äò/v1/audio/translations‚Äô]
   </td>
  </tr>
  <tr>
   <td>‚úîÔ∏è
   </td>
   <td>text-moderation-007
   </td>
   <td>Text Moderation (Latest)
   </td>
   <td>Most capable moderation model across all categories.
   </td>
   <td>openai
   </td>
   <td>1
   </td>
   <td>No
   </td>
   <td>32768
   </td>
   <td>32768
   </td>
   <td>No
   </td>
   <td>No
   </td>
   <td>/v1/moderations
   </td>
  </tr>
  <tr>
   <td>‚úîÔ∏è
   </td>
   <td>text-moderation-007
   </td>
   <td>Text Moderation (Latest)
   </td>
   <td>Most capable moderation model across all categories.
   </td>
   <td>openai
   </td>
   <td>1
   </td>
   <td>No
   </td>
   <td>32768
   </td>
   <td>32768
   </td>
   <td>No
   </td>
   <td>No
   </td>
   <td>/v1/moderations
   </td>
  </tr>
  <tr>
   <td>‚úîÔ∏è
   </td>
   <td>text-moderation-007
   </td>
   <td>Text Moderation (Latest)
   </td>
   <td>Most capable moderation model across all categories.
   </td>
   <td>openai
   </td>
   <td>1
   </td>
   <td>No
   </td>
   <td>32768
   </td>
   <td>32768
   </td>
   <td>No
   </td>
   <td>No
   </td>
   <td>/v1/moderations
   </td>
  </tr>
  <tr>
   <td>‚úîÔ∏è
   </td>
   <td>joke-1
   </td>
   <td>Joke 1
   </td>
   <td>Some jokes.
   </td>
   <td>shuttleai
   </td>
   <td>1
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>/v1/jokes
   </td>
  </tr>
  <tr>
   <td>‚úîÔ∏è
   </td>
   <td>insult-1
   </td>
   <td>Insult 1
   </td>
   <td>Some insults.
   </td>
   <td>shuttleai
   </td>
   <td>1
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>/v1/insults
   </td>
  </tr>
  <tr>
   <td>üí∞
   </td>
   <td>search-google
   </td>
   <td>Search Google
   </td>
   <td>Search Google for anything. Different from search-ddg in that it supports language filtering and image searching.
   </td>
   <td>google
   </td>
   <td>2
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>/v1/web-search
   </td>
  </tr>
  <tr>
   <td>üí∞
   </td>
   <td>search-google
   </td>
   <td>Search Google
   </td>
   <td>Search Google for anything. Different from search-ddg in that it supports language filtering and image searching.
   </td>
   <td>google
   </td>
   <td>2
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>/v1/web-search
   </td>
  </tr>
  <tr>
   <td>‚úîÔ∏è
   </td>
   <td>search-ddg
   </td>
   <td>Search DuckDuckGo
   </td>
   <td>Search DuckDuckGo. Only english natively, no image search. Web results only.
   </td>
   <td>duckduckgo
   </td>
   <td>1
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>nan
   </td>
   <td>/v1/web-search
   </td>
  </tr>
  <tr>
   <td>‚úîÔ∏è
   </td>
   <td>search-ddg
   </td>
   <td>Search DuckDuckGo
   </td>
   <td>Search DuckDuckGo. Only english natively, no image search. Web results only.
   </td>
   <td>duckduckgo
   </td>
   <td>1
   </td>
   <td>nan
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>
   </td>
  </tr>
</table>
